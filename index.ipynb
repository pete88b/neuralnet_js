{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regulated-proceeding",
   "metadata": {},
   "source": [
    "# Neural net js\n",
    "\n",
    "> The goal of this project is implement a neural net in javascript that is as easy to understand as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-mistress",
   "metadata": {},
   "source": [
    "This project will also look at using an [nbdev](https://github.com/fastai/nbdev/) style of library development using [tslab](https://github.com/yunabe/tslab) to provide a js kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-isolation",
   "metadata": {},
   "source": [
    "## Live demo\n",
    "\n",
    "This [gist via bl.ocks](https://bl.ocks.org/pete88b/2aa60d189006bba7c59039f1e9d55936) shows how a model, learning in browser, converges with a 3d scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-burke",
   "metadata": {},
   "source": [
    "# Quick example\n",
    "\n",
    "Let's train a classifier using [iris.data](https://archive.ics.uci.edu/ml/datasets/iris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "muslim-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import {argmax} from './src/util.module.js';\n",
    "import {head,tail,parseCsv,IRIS_CLASS_MAP,IrisRowHandler} from './src/data.module.js';\n",
    "import {BinaryCrossEntropyLoss,Linear,Sigmoid,ReLU,Learner} from './src/nn.module.js';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifteen-camping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -1 valid loss 0.5903966819442324 metrics [ 0.5666666666666667 ]\n",
      "epoch 0 valid loss 0.3407337096444165 metrics [ 0.7333333333333333 ]\n",
      "epoch 1 valid loss 0.2862552656446179 metrics [ 0.7666666666666667 ]\n",
      "epoch 2 valid loss 0.25977964626282773 metrics [ 0.8333333333333334 ]\n",
      "epoch 3 valid loss 0.2425962174061848 metrics [ 0.8333333333333334 ]\n",
      "epoch 4 valid loss 0.23052460534422084 metrics [ 0.8666666666666667 ]\n",
      "epoch 5 valid loss 0.2219764850003557 metrics [ 0.8666666666666667 ]\n",
      "epoch 6 valid loss 0.2155868764802235 metrics [ 0.8666666666666667 ]\n",
      "epoch 7 valid loss 0.2100849828904428 metrics [ 0.8666666666666667 ]\n",
      "epoch 8 valid loss 0.20451255769038718 metrics [ 0.8666666666666667 ]\n",
      "epoch 9 valid loss 0.19991713342679168 metrics [ 0.8666666666666667 ]\n",
      "epoch 10 valid loss 0.19631987142339363 metrics [ 0.8666666666666667 ]\n",
      "epoch 11 valid loss 0.19247678235149668 metrics [ 0.8666666666666667 ]\n",
      "epoch 12 valid loss 0.18867427254256755 metrics [ 0.8666666666666667 ]\n",
      "epoch 13 valid loss 0.1862439672262243 metrics [ 0.8666666666666667 ]\n",
      "epoch 14 valid loss 0.18353223927695927 metrics [ 0.8666666666666667 ]\n",
      "epoch 15 valid loss 0.18093770581985008 metrics [ 0.8666666666666667 ]\n",
      "epoch 16 valid loss 0.17714412554466286 metrics [ 0.8666666666666667 ]\n",
      "epoch 17 valid loss 0.1747827590673882 metrics [ 0.8666666666666667 ]\n",
      "epoch 18 valid loss 0.17218218246174313 metrics [ 0.8666666666666667 ]\n",
      "epoch 19 valid loss 0.17280705924779272 metrics [ 0.8666666666666667 ]\n",
      "epoch 20 valid loss 0.1706987966615525 metrics [ 0.8666666666666667 ]\n",
      "epoch 21 valid loss 0.1694522741937187 metrics [ 0.8666666666666667 ]\n",
      "epoch 22 valid loss 0.1662862109824293 metrics [ 0.8666666666666667 ]\n",
      "epoch 23 valid loss 0.1640803760481836 metrics [ 0.8666666666666667 ]\n",
      "epoch 24 valid loss 0.1613141072248946 metrics [ 0.8666666666666667 ]\n"
     ]
    }
   ],
   "source": [
    "let stringData=require('fs').readFileSync('data/iris.data').toString();\n",
    "let data=parseCsv(stringData, new IrisRowHandler()).result;\n",
    "let lossFn=new BinaryCrossEntropyLoss();\n",
    "let model=[new Linear(4,50), new ReLU(), new Linear(50,3), new Sigmoid()];\n",
    "let learn=new Learner(model, lossFn, data);\n",
    "learn.fit(25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-virginia",
   "metadata": {},
   "source": [
    "We can look at predictions our trained model makes on the validation data.\n",
    "\n",
    "For each row, `learn.predict` gives us `[preds, predicted label, actual label]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dynamic-joseph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3 [\n",
      "  [ 0.00061238812657286, 0.19764246030216065, 0.8763671384120886 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "-2 [\n",
      "  [ 0.0034785677047756308, 0.2603165853376491, 0.7657497145240926 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "-1 [\n",
      "  [ 0.9928633203666908, 0.014137138112522535, 0.00435879637193152 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "let preds=learn.predict(learn.xValid, learn.yValid, (y=>`${argmax(y)}: ${IRIS_CLASS_MAP[argmax(y)]}`));\n",
    "tail(preds,3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-parks",
   "metadata": {},
   "source": [
    "and we can easily make up some data of our own and see what the model predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aboriginal-minority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    [ 0.1230832698012669, 0.020098951596435544, 0.014637429800718547 ],\n",
      "    '0: Iris-setosa',\n",
      "    '0: Iris-setosa'\n",
      "  ],\n",
      "  [\n",
      "    [ 0.2650451679496162, 0.44993355141353014, 0.135656747558312 ],\n",
      "    '1: Iris-versicolor',\n",
      "    '1: Iris-versicolor'\n",
      "  ],\n",
      "  [\n",
      "    [\n",
      "      0.9766828277236442,\n",
      "      0.00001019703456778939,\n",
      "      0.000003005658805141498\n",
      "    ],\n",
      "    '0: Iris-setosa',\n",
      "    '2: Iris-virginica'\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "let rh=new IrisRowHandler();\n",
    "rh.handleRow('5.5,3.5,10.4,0.2,Iris-setosa');\n",
    "rh.handleRow('5.5,2.6,0.4,1.2,Iris-versicolor');\n",
    "rh.handleRow('0.5,3.0,5.1,1.8,Iris-virginica');\n",
    "learn.predict(...rh.result, (y=>`${argmax(y)}: ${IRIS_CLASS_MAP[argmax(y)]}`));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-objective",
   "metadata": {},
   "source": [
    "## Setting up a development environment\n",
    "\n",
    "This project uses the [tslab Dockerfile for running on mybinder.org](https://github.com/yunabe/tslab-examples/blob/master/Dockerfile_prebuilt).\n",
    "\n",
    "```\n",
    "git clone https://github.com/pete88b/neuralnet_js.git\n",
    "cd neuralnet_js\n",
    "docker build -t neuralnet_js .\n",
    "docker run -d -p 8888:8888 -p 8000:8000 --mount type=bind,source=\"<absolute path to neuralnet_js on your machine>\",target=/home/node/tslab-examples neuralnet_js\n",
    "```\n",
    "Check the container logs for a section that looks a bit like;\n",
    "```\n",
    "To access the notebook, open this file in a browser:\n",
    "file:///home/node/.local/share/jupyter/runtime/nbserver-1-open.html\n",
    "Or copy and paste one of these URLs:\n",
    "http://4f1ee683b96c:8888/?token=b3dd4ed644617cfb795dd8eb899aafea4c2168d8dc897357\n",
    "or http://127.0.0.1:8888/?token=b3dd4ed644617cfb795dd8eb899aafea4c2168d8dc897357\n",
    "```\n",
    "Copy the `127.0.0.1` URL and paste it into your browser.\n",
    "\n",
    "Note: The `docker run` command above uses 2 ports;\n",
    "- 8888 for jupyter and\n",
    "- 8000 which we can use to view demo web pages with http://localhost:8000/demo/\n",
    "    - Run `python3 -m http.server 8000` from a jupyter terminal to start the http server\n",
    "    - we manually start the server so that we don't have to change Dockerfile\n",
    "\n",
    "If you'd like to work with the tslab-examples, just docker run without the --mount;\n",
    "```\n",
    "docker run -d -p 8888:8888 neuralnet_js\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-company",
   "metadata": {},
   "source": [
    "## Converting notebooks to javascript files\n",
    "\n",
    "From a jupyter terminal you can;\n",
    "\n",
    "`$ python3 nbdev_js.py`\n",
    "```\n",
    "Converting 00_testutil.ipynb to src/testutil.js\n",
    "Converting 00_testutil.ipynb to src/testutil.module.js\n",
    "...\n",
    "Converting index.ipynb to README.md\n",
    "```\n",
    "\n",
    "Note: I've added a local file `mk` so I only have to type `./mk` at the terminal.\n",
    "\n",
    "See: `99_nbdev_js.ipynb` for notebook conversion details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "jslab"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "text/javascript",
   "name": "javascript",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
