{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinct-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "//default_exp nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-restaurant",
   "metadata": {},
   "source": [
    "# nn\n",
    "\n",
    "> A few modules that can be used to build neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "marine-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Imports we need in nn.module.js\n",
    "*/\n",
    "import {exp,shape,transpose,dotProduct,randn,uniform,zeros,argmax,mean,round} from './src/util.module.js';\n",
    "import {matrixSum1d,matrixSum2d,matrixSubtract1d,matrixSubtract2d,matrixMultiply1d,matrixMultiply2d} from './src/util.module.js';\n",
    "import {head,tail,parseCsv,IRIS_CLASS_MAP,IrisRowHandler,shuffle,split,batches} from './src/data.module.js';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enormous-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Imports we need for testing\n",
    "import {testEq} from './src/testutil.module.js'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compliant-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "yTrue can be either 2d (one-hot encoded targets) or 1d (array of class IDs).\n",
    "*/\n",
    "function accuracy(yPred2d,yTrue) {\n",
    "    const yPredShape=shape(yPred2d);\n",
    "    const yTrueShape=shape(yTrue);\n",
    "    if (yPredShape[0] != yTrueShape[0]) {\n",
    "        throw new Error(`Expected yPred2d.length ${yPredShape[0]} to equal yTrue.length ${yTrueShape[0]}`);\n",
    "    }\n",
    "    if (yTrueShape.length == 2 && yPredShape[1] != yTrueShape[1]) {\n",
    "        throw new Error(`Expected shape(yPred2d)[1] ${yPredShape[1]} to equal shape(yTrue)[1] ${yTrueShape[1]}`);\n",
    "    }\n",
    "    let correctCount=0;\n",
    "    for (let i=0; i<yPred2d.length; i++) {\n",
    "        let p = argmax(yPred2d[i]);\n",
    "        let t = (yTrueShape.length == 2) ? argmax(yTrue[i]) : yTrue[i];\n",
    "        if (p == t) {\n",
    "            correctCount++;\n",
    "        }\n",
    "    }\n",
    "    return correctCount/yPredShape[0];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recovered-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "let yPred=[[0,.1],[0,.9],[0,.33],[0,1],[0,1],[0,1],[0,1],[0,1],[1,0]];\n",
    "let yTrue=[[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[1,0]];\n",
    "testEq(1.0, accuracy(yPred,yTrue));\n",
    "yPred[0][0]=.8;\n",
    "testEq(8/9, accuracy(yPred,yTrue));\n",
    "yPred.map(a=>a[0]=1.1); // accuracy doesn't care if we're not within 0 and 1\n",
    "testEq(1/9, accuracy(yPred,yTrue));\n",
    "// test with class IDs\n",
    "testEq(1/9, accuracy(yPred,[1,1,1,1,1,1,1,1,0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daily-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class MSE {\n",
    "    forward(yPred2d,yTrue2d) {\n",
    "        this.error=matrixSubtract2d(yPred2d,yTrue2d);\n",
    "        return mean(this.error.map(row=>row.map(elem=>elem**2)));\n",
    "    }\n",
    "    backward() {\n",
    "        this.grad=matrixMultiply2d(this.error, 2/this.error.length);\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intelligent-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "let mse=new MSE();\n",
    "let mseValue=mse.forward(\n",
    "    [[-0.1684, -1.0158, -1.3667,  1.4327],\n",
    "    [ 0.0245, -0.6284, -2.5182,  2.2007],\n",
    "    [-1.8774, -0.0352, -0.5946,  0.4272]],\n",
    "    [[-0.3516,  0.5787,  0.8858,  0.9198],\n",
    "    [ 0.1892, -0.6473,  2.1278,  0.1345],\n",
    "    [ 2.2919, -0.9939, -0.3137, -0.4314]]);\n",
    "testEq(4.409, Math.round(mseValue*1000)/1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-shakespeare",
   "metadata": {},
   "source": [
    "## cross entropy: negative log likelyhood of log softmax\n",
    "\n",
    "The following is taken from https://github.com/fastai/course-v3/blob/master/nbs/dl2/03_minibatch_training.ipynb\n",
    "```\n",
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()\n",
    "\n",
    "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)\n",
    "\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "twenty-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Takes a 2d array and returns a 1d array of the log of the sum of the exp for each row.\n",
    "*/\n",
    "function logsumexp(x) {\n",
    "    const m = x.map(a => Math.max(...a));\n",
    "    let temp = x.map((row,i) => row.map(e => e-m[i])); // x-m[:,None]\n",
    "    temp = temp.map(row => row.map(e => exp(e)));      // .exp()\n",
    "    temp = temp.map(row => row.reduce((a,b) => a+b))   // .sum(-1)\n",
    "    temp = temp.map(a => Math.log(a));                 // .log()\n",
    "    return matrixSum1d(m, temp);                       // return m + ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "provincial-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "let testData=[[1.6392130817141863, 0.12928212984246149],\n",
    "              [0.000843200027605633, -0.12680858189363003],\n",
    "              [-0.9898354893794594, -1.5028466126461082]]\n",
    "testEq([1.8388, 0.6322, -0.5207], round(logsumexp(testData),4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indie-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Takes a 2d array and returns a 2d array of log softmax for each element.\n",
    "*/\n",
    "function log_softmax(x) {\n",
    "    const _logsumexp = logsumexp(x);\n",
    "    return x.map((row,i) => row.map(e => e-_logsumexp[i]));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "raising-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEq([[-0.1996089581238054, -1.7095399099955302],\n",
    "        [-0.6313567803288485, -0.7590085622500842],\n",
    "        [-0.4691846265662769, -0.9821957498329257]], log_softmax(testData));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "angry-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Takes a 2d input (log softmax predictions) and a 1d array of target class IDs and returns the negative log likelihood.\n",
    "*/\n",
    "function nll(input, target) {\n",
    "    return -mean(input.map((row,i) => row[target[i]]));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "residential-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEq(-0.2167, round(nll(testData,[0,0,0]),4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-rugby",
   "metadata": {},
   "source": [
    "`CrossEntropyLoss` uses an approach borrowed from https://beckernick.github.io/logistic-regression-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "simple-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Cross entropy with softmax.\n",
    "yTrue1d is an array of target class IDs - not a 2d array of 1 hot encoded targets.\n",
    "*/\n",
    "class CrossEntropyLoss {\n",
    "    softmax1d(a) {\n",
    "        const maxValue=Math.max(...a); // normalize values for numerical stability (log sum exp)\n",
    "        const temp=a.map(e => exp(e-maxValue));\n",
    "        const sum=temp.reduce((a,b)=>a+b);\n",
    "        return temp.map(e=>e/sum);\n",
    "    }\n",
    "        \n",
    "    forward(yPred2d,yTrue1d) {\n",
    "        this.yPred2d=yPred2d.map(yPred1d => this.softmax1d(yPred1d));\n",
    "        this.yTrue1d=yTrue1d;\n",
    "        const temp=this.yPred2d.map((yPred1d,i) => Math.log(yPred1d[yTrue1d[i]])); // TODO: add tiny value to avoid log(0)\n",
    "        return -temp.reduce((a,b) => a+b) / temp.length;\n",
    "    }\n",
    "    \n",
    "    backward() {\n",
    "        const yTrue1d=this.yTrue1d;\n",
    "        this.grad=this.yPred2d.map(yPred1d => [...yPred1d]); // copy preds\n",
    "        this.grad.forEach((yPred1d,i)=>yPred1d[yTrue1d[i]]-=1);\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coated-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "// show that both ways of calculating cross entropy loss give the same values\n",
    "let lossFn = new CrossEntropyLoss()\n",
    "testEq(round(nll(log_softmax(testData),[0,0,0]),4), round(lossFn.forward(testData,[0,0,0]),4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suitable-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class BinaryCrossEntropyLoss {\n",
    "    _forward1d(yPred1d,yTrue1d) {\n",
    "        const temp=yPred1d.map((yPred,i) => Math.log((yTrue1d[i]==1.) ? yPred : 1-yPred));\n",
    "        return -temp.reduce((a,b) => a+b) / temp.length;\n",
    "    }\n",
    "    forward(yPred2d,yTrue2d) {\n",
    "        this.yPred2d=yPred2d;\n",
    "        this.yTrue2d=yTrue2d;\n",
    "        const lossValue1d=yPred2d.map((yPred1d,i) => this._forward1d(yPred1d,yTrue2d[i]));\n",
    "        return lossValue1d.reduce((a,b) => a+b) / lossValue1d.length;\n",
    "    }\n",
    "    _backward1d(yPred1d,yTrue1d) {\n",
    "        return yPred1d.map((yPred,i) => (yTrue1d[i]==1.) ? -1/yPred : 1/(1-yPred));\n",
    "    }\n",
    "    backward() {\n",
    "        const yTrue2d=this.yTrue2d;\n",
    "        this.grad=this.yPred2d.map((yPred1d,i) => this._backward1d(yPred1d,yTrue2d[i]));\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "covered-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Sigmoid {\n",
    "    forward(x2d) {\n",
    "        this.results=x2d.map(x1d => x1d.map(x => 1./(1.+exp(-x))));\n",
    "        return this.results;\n",
    "    }\n",
    "    backward(gradients) {\n",
    "        // `s * (1.-s)` calculates sigmoid grad, then we chain gradients passed in\n",
    "        this.grad=this.results.map((result,i) => result.map((s,j) => s * (1.-s) * gradients[i][j]));\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "passing-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class ReLU {\n",
    "    forward(x2d) {\n",
    "        this.gradMask=zeros(...shape(x2d));\n",
    "        return x2d.map((x1d,rowIndex) => x1d.map((x,colIndex) => {\n",
    "            if (x>0) {\n",
    "                this.gradMask[rowIndex][colIndex]=1;\n",
    "            }\n",
    "            return Math.max(0,x);\n",
    "        }));\n",
    "    }\n",
    "    backward(gradient) {\n",
    "        return matrixMultiply2d(this.gradMask,gradient);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "attempted-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "let relu = new ReLU();\n",
    "let data = [\n",
    "  [ -0.3132450550822199, 0.06746248970796562, 0.7502210053477679 ],\n",
    "  [ 0.32586239499711434, 0.276573231917191, 0.4718188033994297 ],\n",
    "  [ 0.3375259522729109, -1.4738907605515226, -0.11109898767917284 ],\n",
    "  [ -0.6095143988686595, 1.094470501593892, -0.4982351760328258 ],\n",
    "  [ 0.28664244098736347, -0.35879217465991975, -0.754257906608068 ]\n",
    "];\n",
    "testEq(relu.forward(data),relu.backward(data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imported-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Applies a linear transformation to `x`.\n",
    "*/\n",
    "class Linear {\n",
    "    constructor(inputDim,numHidden=1,bias=true) {\n",
    "        this.inputDim=inputDim;\n",
    "        this.numHidden=numHidden;\n",
    "        // Kaiming Init\n",
    "        this.weights=matrixMultiply2d(randn(inputDim,numHidden), Math.sqrt(2.0/inputDim));\n",
    "        this.bias=zeros(numHidden)\n",
    "        this.updateBias=bias;\n",
    "    }\n",
    "    forward(x) {\n",
    "        this.x=x; // shape(bs,inputDim)\n",
    "        return matrixSum2d(dotProduct(x,this.weights), this.bias);\n",
    "    }\n",
    "    backward(gradient) { // gradient shape(bs,numHidden)\n",
    "        // weightsGradient/biasGradient need to be the same shape as weights/bias\n",
    "        this.weightsGradient=dotProduct(transpose(this.x), gradient);\n",
    "        // this.biasGradient=gradient.sum(axis=0)\n",
    "        this.biasGradient=transpose(gradient).map(col => col.reduce((a,b) => a+b));\n",
    "        this.xGradient=dotProduct(gradient,transpose(this.weights));\n",
    "        return this.xGradient;\n",
    "    }\n",
    "    update(lr) {\n",
    "        // gradient calculations in backward don't account for batch size, so we do it here\n",
    "        lr=lr/this.x.length; // TODO: change gradient calc to account for batch size - all XxxLoss classes\n",
    "        this.weights=matrixSubtract2d(this.weights,matrixMultiply2d(this.weightsGradient,lr));\n",
    "        if (this.updateBias) {\n",
    "            this.bias=matrixSubtract1d(this.bias,matrixMultiply1d(this.biasGradient,lr));\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "possible-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Using\n",
    "- `Embedding` when `x` is an array of IDs or\n",
    "- `Linear` when `x` is a one-hot encoded matrix\n",
    "should give the same results - but `Embedding` should be faster.\n",
    "*/\n",
    "class Embedding extends Linear {\n",
    "    constructor(inputDim,numHidden=1,bias=true) {\n",
    "        super(inputDim,numHidden,bias);\n",
    "        this.weights=uniform(inputDim,numHidden,-1,1);\n",
    "    }\n",
    "    forward(x) {\n",
    "        this.x=x;\n",
    "        return matrixSum2d(x.map(i=>this.weights[i]), this.bias);\n",
    "    }\n",
    "    backward(gradient) { // gradient shape(bs,numHidden)\n",
    "        this.weightsGradient=zeros(this.inputDim,this.numHidden);\n",
    "        for (let i=0; i<this.inputDim; i++) {\n",
    "            this.x.map((row, rowIndex)=>{\n",
    "                if (row == i) {\n",
    "                    this.weightsGradient[i]=matrixSum1d(this.weightsGradient[i],gradient[rowIndex]);\n",
    "                }\n",
    "            })\n",
    "        }\n",
    "        this.biasGradient=transpose(gradient).map(col => col.reduce((a,b) => a+b));\n",
    "        this.xGradient=dotProduct(gradient,transpose(this.weights));\n",
    "        return this.xGradient;\n",
    "    }\n",
    "    update(lr) {\n",
    "        // gradient calculations in backward don't account for batch size, so we do it here\n",
    "        lr=lr/this.x.length; // TODO: change gradient calc to account for batch size - all XxxLoss classes\n",
    "        this.weights=matrixSubtract2d(this.weights,matrixMultiply2d(this.weightsGradient,lr));\n",
    "        if (this.updateBias) {\n",
    "            this.bias=matrixSubtract1d(this.bias,matrixMultiply1d(this.biasGradient,lr));\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-argentina",
   "metadata": {},
   "source": [
    "The following shows that `Linear` and `Embedding` apply the same transformation and calculate the same gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hearing-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "var inputDim=3;\n",
    "var numHidden=5\n",
    "let linear=new Linear(inputDim, numHidden);\n",
    "let embedding=new Embedding(inputDim, numHidden);\n",
    "linear.weights=JSON.parse(JSON.stringify(embedding.weights));\n",
    "\n",
    "let embedding_in=[0,1,2,1];\n",
    "let bs=embedding_in.length;\n",
    "let linear_in=zeros(bs, inputDim);\n",
    "embedding_in.forEach((e,i)=>linear_in[i][e]=1);\n",
    "testEq(linear.forward(linear_in),embedding.forward(embedding_in));\n",
    "\n",
    "let gradient=randn(bs,numHidden);\n",
    "linear.backward(gradient);\n",
    "embedding.backward(gradient);\n",
    "testEq(linear.weightsGradient, embedding.weightsGradient);\n",
    "testEq(linear.biasGradient, embedding.biasGradient);\n",
    "testEq(linear.xGradient, embedding.xGradient);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accomplished-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Learner {\n",
    "    constructor(model, lossFn, data, metrics=[accuracy]) {\n",
    "        this.model=model;\n",
    "        this.lossFn=lossFn;\n",
    "        this.metrics=metrics;\n",
    "        const splitData=split(shuffle(data));\n",
    "        this.xTrain=splitData[0][0];\n",
    "        this.xValid=splitData[0][1];\n",
    "        this.yTrain=splitData[1][0];\n",
    "        this.yValid=splitData[1][1];\n",
    "        // shame that we can destructure into this. )o:\n",
    "//         [[this.xTrain,this.xValid],[this.yTrain,this.yValid]]=split(data);\n",
    "    }\n",
    "    forward(x) {\n",
    "        for (let i=0; i<this.model.length; i++) {\n",
    "            x=this.model[i].forward(x);\n",
    "        }\n",
    "        return x;\n",
    "    }\n",
    "    backward(gradients) {\n",
    "        for (let i=this.model.length-1; i>=0; i--) {\n",
    "            gradients=this.model[i].backward(gradients);\n",
    "        }\n",
    "        return gradients;\n",
    "    }\n",
    "    step(lr) {\n",
    "        this.model.forEach(m => {\n",
    "            if (typeof m.update=='function') {\n",
    "                m.update(lr);\n",
    "            }\n",
    "        });\n",
    "    }\n",
    "    validate(epoch) {\n",
    "        const preds=this.forward(this.xValid);\n",
    "        const lossValue=this.lossFn.forward(preds,this.yValid);\n",
    "        const metricValues=this.metrics.map(metric=>metric(preds,this.yValid));\n",
    "        console.log('epoch',epoch,'valid loss',lossValue,'metrics',metricValues);\n",
    "    }\n",
    "    fit(epochs, lr=0.1, bs=64) {\n",
    "        this.validate(-1); // Note: we use epoch -1 to indicate before training\n",
    "        for (let epoch=0; epoch<epochs; epoch++) {\n",
    "            batches([this.xTrain,this.yTrain]).forEach(batch => {\n",
    "                const [xb,yb]=batch;\n",
    "                const preds=this.forward(xb);\n",
    "                const lossValue=this.lossFn.forward(preds,yb);\n",
    "                this.lossFn.backward();\n",
    "                this.backward(this.lossFn.grad);\n",
    "                this.step(lr);\n",
    "            });\n",
    "            this.validate(epoch);\n",
    "        }\n",
    "    }\n",
    "    predict(x,y,yToLabelFn=(a=>a)) {\n",
    "        const preds=this.forward(x);\n",
    "        return preds.map((pred,rowIndex) => {\n",
    "            const row=[pred,yToLabelFn(pred)];\n",
    "            if (y!=null) {\n",
    "                row.push(yToLabelFn(y[rowIndex]));\n",
    "            }\n",
    "            return row;\n",
    "        });\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-compilation",
   "metadata": {},
   "source": [
    "## Train a linear model to classify iris flowers\n",
    "\n",
    "Note: we use `BinaryCrossEntropyLoss` here just as an example. README.md and index.ipynb shows how to train with `CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "agreed-publication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -1 valid loss 0.9109090304204185 metrics [ 0.26666666666666666 ]\n",
      "epoch 0 valid loss 0.8099330011050551 metrics [ 0.26666666666666666 ]\n",
      "epoch 1 valid loss 0.7254364984214408 metrics [ 0.3 ]\n",
      "epoch 2 valid loss 0.6569570399645729 metrics [ 0.5 ]\n",
      "epoch 3 valid loss 0.6031691548791043 metrics [ 0.5 ]\n",
      "epoch 4 valid loss 0.5614477140559698 metrics [ 0.6 ]\n",
      "epoch 5 valid loss 0.529146473484039 metrics [ 0.7 ]\n",
      "epoch 6 valid loss 0.5043085122388226 metrics [ 0.7 ]\n",
      "epoch 7 valid loss 0.4849431608039424 metrics [ 0.7333333333333333 ]\n",
      "epoch 8 valid loss 0.46965031567839827 metrics [ 0.7333333333333333 ]\n",
      "epoch 9 valid loss 0.457001658109672 metrics [ 0.7333333333333333 ]\n",
      "epoch 10 valid loss 0.4459796482305391 metrics [ 0.7333333333333333 ]\n",
      "epoch 11 valid loss 0.4372260391400424 metrics [ 0.7333333333333333 ]\n",
      "epoch 12 valid loss 0.42944545438344767 metrics [ 0.7333333333333333 ]\n",
      "epoch 13 valid loss 0.42270065210260477 metrics [ 0.7333333333333333 ]\n",
      "epoch 14 valid loss 0.4165616651757987 metrics [ 0.7333333333333333 ]\n",
      "epoch 15 valid loss 0.41129932835795174 metrics [ 0.7333333333333333 ]\n",
      "epoch 16 valid loss 0.4065765349689706 metrics [ 0.7333333333333333 ]\n",
      "epoch 17 valid loss 0.4023850093182319 metrics [ 0.7333333333333333 ]\n",
      "epoch 18 valid loss 0.3985041848919468 metrics [ 0.7333333333333333 ]\n",
      "epoch 19 valid loss 0.39476914259357637 metrics [ 0.7333333333333333 ]\n",
      "epoch 20 valid loss 0.39122379472484575 metrics [ 0.7333333333333333 ]\n",
      "epoch 21 valid loss 0.3881476861692611 metrics [ 0.7333333333333333 ]\n",
      "epoch 22 valid loss 0.385317391709213 metrics [ 0.7333333333333333 ]\n",
      "epoch 23 valid loss 0.3825930585060087 metrics [ 0.7333333333333333 ]\n",
      "epoch 24 valid loss 0.37998176331902755 metrics [ 0.7333333333333333 ]\n"
     ]
    }
   ],
   "source": [
    "let stringData=require('fs').readFileSync('data/iris.data').toString();\n",
    "let data=parseCsv(stringData, new IrisRowHandler()).result;\n",
    "let lossFn=new BinaryCrossEntropyLoss();\n",
    "let model=[new Linear(4,3), new Sigmoid()];\n",
    "let learn=new Learner(model, lossFn, data);\n",
    "learn.fit(25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-cleaner",
   "metadata": {},
   "source": [
    "## Train a neural net to classify iris flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "disabled-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -1 valid loss 0.6983069062925652 metrics [ 0.4666666666666667 ]\n",
      "epoch 0 valid loss 0.4096526196336277 metrics [ 0.7 ]\n",
      "epoch 1 valid loss 0.37116439964170433 metrics [ 0.7333333333333333 ]\n",
      "epoch 2 valid loss 0.34691951302918655 metrics [ 0.7333333333333333 ]\n",
      "epoch 3 valid loss 0.3301522572207321 metrics [ 0.8 ]\n",
      "epoch 4 valid loss 0.31664335621564643 metrics [ 0.8 ]\n",
      "epoch 5 valid loss 0.3056892179970104 metrics [ 0.8 ]\n",
      "epoch 6 valid loss 0.2966833605517909 metrics [ 0.8 ]\n",
      "epoch 7 valid loss 0.2911649176860406 metrics [ 0.8 ]\n",
      "epoch 8 valid loss 0.2848935842362169 metrics [ 0.8 ]\n",
      "epoch 9 valid loss 0.279592437884924 metrics [ 0.8 ]\n",
      "epoch 10 valid loss 0.27462301274116585 metrics [ 0.8 ]\n",
      "epoch 11 valid loss 0.270675603950377 metrics [ 0.8 ]\n",
      "epoch 12 valid loss 0.2651677596225735 metrics [ 0.8 ]\n",
      "epoch 13 valid loss 0.2616001690962012 metrics [ 0.8 ]\n",
      "epoch 14 valid loss 0.2569000128382096 metrics [ 0.8 ]\n",
      "epoch 15 valid loss 0.2547780795245656 metrics [ 0.8 ]\n",
      "epoch 16 valid loss 0.2513356850640857 metrics [ 0.8 ]\n",
      "epoch 17 valid loss 0.24840005883824692 metrics [ 0.8333333333333334 ]\n",
      "epoch 18 valid loss 0.24662538740354464 metrics [ 0.8333333333333334 ]\n",
      "epoch 19 valid loss 0.2431347711765529 metrics [ 0.8333333333333334 ]\n",
      "epoch 20 valid loss 0.24210760216780186 metrics [ 0.8333333333333334 ]\n",
      "epoch 21 valid loss 0.23949598576387662 metrics [ 0.8333333333333334 ]\n",
      "epoch 22 valid loss 0.23661357806906252 metrics [ 0.8333333333333334 ]\n",
      "epoch 23 valid loss 0.23582337592357383 metrics [ 0.8333333333333334 ]\n",
      "epoch 24 valid loss 0.2348955046993697 metrics [ 0.8333333333333334 ]\n"
     ]
    }
   ],
   "source": [
    "let model=[new Linear(4,50), new ReLU(), new Linear(50,3), new Sigmoid()];\n",
    "let learn=new Learner(model, lossFn, data);\n",
    "learn.fit(25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-coordination",
   "metadata": {},
   "source": [
    "### Look at some predictions \n",
    "\n",
    "We use the lambda ```(y=>`${argmax(y)}: ${IRIS_CLASS_MAP[argmax(y)]}`)``` to convert predictions like `[0.000, 0.183, 0.843]` to readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sensitive-checkout",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [\n",
      "  [ 0.06423957178856468, 0.18659442021358044, 0.809785959867297 ],\n",
      "  '2: Iris-virginica',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "1 [\n",
      "  [ 0.9984373014569424, 0.005217967220236772, 0.002201774761163568 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "2 [\n",
      "  [ 0.9771091594700118, 0.024259395882655306, 0.00273577528669128 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "3 [\n",
      "  [ 0.0350655771226941, 0.8436276427873515, 0.05686654528132866 ],\n",
      "  '1: Iris-versicolor',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "4 [\n",
      "  [ 0.997157938906728, 0.009618056835112947, 0.0035352570500683917 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "5 [\n",
      "  [ 0.01690222876081816, 0.4580457037148286, 0.6482480428373324 ],\n",
      "  '2: Iris-virginica',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "6 [\n",
      "  [ 0.0022571328639988033, 0.7361375740654459, 0.2820925870802532 ],\n",
      "  '1: Iris-versicolor',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "7 [\n",
      "  [ 0.010447129598920581, 0.2404578763927446, 0.7768037213041088 ],\n",
      "  '2: Iris-virginica',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "8 [\n",
      "  [ 0.0008017431765991797, 0.013955143715761774, 0.956762225970552 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "9 [\n",
      "  [ 0.0836763656657711, 0.7523026033059722, 0.1987172996330681 ],\n",
      "  '1: Iris-versicolor',\n",
      "  '1: Iris-versicolor'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "// head(learn.predict(learn.xValid, learn.yValid)); run this to see \"raw\" targets\n",
    "head(learn.predict(learn.xValid, learn.yValid, (y=>`${argmax(y)}: ${IRIS_CLASS_MAP[argmax(y)]}`)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-liabilities",
   "metadata": {},
   "source": [
    "Show how we could train a linear layer without `Learner` - this is not a proper training loop, we just;\n",
    "- forward pass\n",
    "- print training loss\n",
    "- backward pass\n",
    "- update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "western-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape(x) [ 150, 4 ] shape(y) [ 150, 3 ]\n",
      "epoch 0 loss_value 0.9479798045352674\n",
      "epoch 1 loss_value 0.8989487627957021\n",
      "epoch 2 loss_value 0.8549446624067516\n",
      "epoch 3 loss_value 0.8154406177269469\n",
      "epoch 4 loss_value 0.7799195599908708\n",
      "epoch 5 loss_value 0.747899259317327\n",
      "epoch 6 loss_value 0.7189454569830287\n",
      "epoch 7 loss_value 0.6926760714352166\n",
      "epoch 8 loss_value 0.6687597778393528\n",
      "epoch 9 loss_value 0.6469116154839275\n"
     ]
    }
   ],
   "source": [
    "let data=parseCsv(stringData, new IrisRowHandler()).result;\n",
    "let x=data[0],y=data[1];\n",
    "console.log('shape(x)',shape(x), 'shape(y)',shape(y));\n",
    "let loss_fn=new BinaryCrossEntropyLoss()\n",
    "let sig=new Sigmoid()\n",
    "let lin=new Linear(4,3);\n",
    "for (let epoch = 0; epoch < 10; epoch++) {\n",
    "    let y_pred=sig.forward(lin.forward(x));\n",
    "    let loss_value=loss_fn.forward(y_pred,y);\n",
    "    console.log('epoch',epoch,'loss_value',loss_value);\n",
    "    loss_fn.backward();\n",
    "    sig.backward(loss_fn.grad);\n",
    "    lin.backward(sig.grad);\n",
    "    lin.update(.1);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-november",
   "metadata": {},
   "source": [
    "## Can we teach a linear layer to convert one hot encoded integers to their bitwise representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "regulated-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "let x=[\n",
    "    [1,0,0,0,0,0,0,0,0,0],\n",
    "    [0,1,0,0,0,0,0,0,0,0],\n",
    "    [0,0,1,0,0,0,0,0,0,0],\n",
    "    [0,0,0,1,0,0,0,0,0,0],\n",
    "    [0,0,0,0,1,0,0,0,0,0],\n",
    "    [0,0,0,0,0,1,0,0,0,0],\n",
    "    [0,0,0,0,0,0,1,0,0,0],\n",
    "    [0,0,0,0,0,0,0,1,0,0],\n",
    "    [0,0,0,0,0,0,0,0,1,0],\n",
    "    [0,0,0,0,0,0,0,0,0,1]\n",
    "];\n",
    "let y=[\n",
    "    [0,0,0,0],\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [1,1,0,0],\n",
    "    [0,0,1,0],\n",
    "    [1,0,1,0],\n",
    "    [0,1,1,0],\n",
    "    [1,1,1,0],\n",
    "    [0,0,0,1],\n",
    "    [1,0,0,1]\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-fight",
   "metadata": {},
   "source": [
    "`x` is an identity matrix, so ... `x.y` is `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sixth-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEq(y,dotProduct(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-count",
   "metadata": {},
   "source": [
    "so ... will `y` make the perfect weights (if bias is zero)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adult-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss_value 0.01826801023638013\n",
      "[\n",
      "  [\n",
      "    0.018241077102381677,\n",
      "    0.017694911550413337,\n",
      "    0.017702128848892752,\n",
      "    0.01848791808616651\n",
      "  ],\n",
      "  [\n",
      "    0.9815339066824532,\n",
      "    0.017844643319954757,\n",
      "    0.018298590220030598,\n",
      "    0.017782599726117673\n",
      "  ],\n",
      "  [\n",
      "    0.018236548558390426,\n",
      "    0.9823281232641801,\n",
      "    0.017986104399842672,\n",
      "    0.017856259579140676\n",
      "  ],\n",
      "  [\n",
      "    0.9822958847767344,\n",
      "    0.9817832453226071,\n",
      "    0.018417317680826203,\n",
      "    0.018288915576708416\n",
      "  ],\n",
      "  [\n",
      "    0.018023018565035534,\n",
      "    0.018497624593485647,\n",
      "    0.982326444561379,\n",
      "    0.018102274095561973\n",
      "  ],\n",
      "  [\n",
      "    0.9816681441318499,\n",
      "    0.017799987666008377,\n",
      "    0.9816486269148199,\n",
      "    0.018436066482178944\n",
      "  ],\n",
      "  [\n",
      "    0.01767397321248599,\n",
      "    0.9818995388186126,\n",
      "    0.9820452630496264,\n",
      "    0.018207926784196908\n",
      "  ],\n",
      "  [\n",
      "    0.9814915726192901,\n",
      "    0.9822346042798649,\n",
      "    0.9817955775220609,\n",
      "    0.018368012355228863\n",
      "  ],\n",
      "  [\n",
      "    0.01816660421112255,\n",
      "    0.017910072882694757,\n",
      "    0.017588670199200736,\n",
      "    0.9815092220420147\n",
      "  ],\n",
      "  [\n",
      "    0.9821967177409593,\n",
      "    0.01824423184569201,\n",
      "    0.018482989838273785,\n",
      "    0.9814969284928386\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "let loss_fn=new BinaryCrossEntropyLoss()\n",
    "let sig=new Sigmoid()\n",
    "let linearNoBias=new Linear(10,4,false);\n",
    "let y_pred=null;\n",
    "for (let epoch = 0; epoch<10; epoch++) {\n",
    "    y_pred=sig.forward(linearNoBias.forward(x));\n",
    "    const loss_value=loss_fn.forward(y_pred,y);\n",
    "    if (epoch%10==9) {\n",
    "        console.log('epoch',epoch,'loss_value',loss_value);\n",
    "    }\n",
    "    loss_fn.backward();\n",
    "    sig.backward(loss_fn.grad);\n",
    "    linearNoBias.backward(sig.grad);\n",
    "    linearNoBias.update(50);\n",
    "}\n",
    "console.log(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-skirt",
   "metadata": {},
   "source": [
    "dump our linear layer to output - so we can look at the learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "statewide-cholesterol",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear {\n",
      "  inputDim: 10,\n",
      "  numHidden: 4,\n",
      "  weights: [\n",
      "    [\n",
      "      -4.076875133127986,\n",
      "      -4.105099383336382,\n",
      "      -4.104720331418261,\n",
      "      -4.0644164714002535\n",
      "    ],\n",
      "    [\n",
      "      4.065510768670068,\n",
      "      -4.097269347731533,\n",
      "      -4.0739561301344,\n",
      "      -4.100505231976311\n",
      "    ],\n",
      "    [\n",
      "      -4.077105394681426,\n",
      "      4.106310282984099,\n",
      "      -4.089936498577871,\n",
      "      -4.096664847256857\n",
      "    ],\n",
      "    [\n",
      "      4.104616036367389,\n",
      "      4.078112572327417,\n",
      "      -4.067961439055957,\n",
      "      -4.074446461425296\n",
      "    ],\n",
      "    [\n",
      "      -4.0880332103261905,\n",
      "      -4.063930233372736,\n",
      "      4.106221979206913,\n",
      "      -4.083960953616492\n",
      "    ],\n",
      "    [\n",
      "      4.072272287508215,\n",
      "      -4.09959714011578,\n",
      "      4.071285896786014,\n",
      "      -4.067018601629332\n",
      "    ],\n",
      "    [\n",
      "      -4.106200004705336,\n",
      "      4.084053888817579,\n",
      "      4.091557107686295,\n",
      "      -4.078562144929315\n",
      "    ],\n",
      "    [\n",
      "      4.0633894019047645,\n",
      "      4.101404658491118,\n",
      "      4.078740671686395,\n",
      "      -4.070445849105483\n",
      "    ],\n",
      "    [\n",
      "      -4.0806696818850705,\n",
      "      -4.093869958601167,\n",
      "      -4.110698485026447,\n",
      "      4.064273180287924\n",
      "    ],\n",
      "    [\n",
      "      4.099425186278315,\n",
      "      -4.076714761229081,\n",
      "      -4.064663452626203,\n",
      "      4.063657496128965\n",
      "    ]\n",
      "  ],\n",
      "  bias: [ 0, 0, 0, 0 ],\n",
      "  updateBias: false,\n",
      "  x: [\n",
      "    [\n",
      "      1, 0, 0, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 1, 0, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 1, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 1, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 1,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      1, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 1, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 1, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 0, 1, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 0, 0, 1\n",
      "    ]\n",
      "  ],\n",
      "  weightsGradient: [\n",
      "    [\n",
      "      0.01824107710238168,\n",
      "      0.017694911550413337,\n",
      "      0.01770212884889275,\n",
      "      0.018487918086166514\n",
      "    ],\n",
      "    [\n",
      "      -0.018466093317546783,\n",
      "      0.01784464331995476,\n",
      "      0.018298590220030598,\n",
      "      0.017782599726117673\n",
      "    ],\n",
      "    [\n",
      "      0.018236548558390426,\n",
      "      -0.017671876735819936,\n",
      "      0.017986104399842672,\n",
      "      0.017856259579140672\n",
      "    ],\n",
      "    [\n",
      "      -0.01770411522326565,\n",
      "      -0.01821675467739292,\n",
      "      0.018417317680826203,\n",
      "      0.018288915576708416\n",
      "    ],\n",
      "    [\n",
      "      0.018023018565035537,\n",
      "      0.018497624593485647,\n",
      "      -0.017673555438621036,\n",
      "      0.018102274095561973\n",
      "    ],\n",
      "    [\n",
      "      -0.018331855868150112,\n",
      "      0.017799987666008377,\n",
      "      -0.01835137308518009,\n",
      "      0.018436066482178944\n",
      "    ],\n",
      "    [\n",
      "      0.01767397321248599,\n",
      "      -0.018100461181387417,\n",
      "      -0.01795473695037364,\n",
      "      0.01820792678419691\n",
      "    ],\n",
      "    [\n",
      "      -0.018508427380709902,\n",
      "      -0.017765395720135135,\n",
      "      -0.018204422477939075,\n",
      "      0.018368012355228863\n",
      "    ],\n",
      "    [\n",
      "      0.018166604211122546,\n",
      "      0.017910072882694757,\n",
      "      0.017588670199200736,\n",
      "      -0.018490777957985264\n",
      "    ],\n",
      "    [\n",
      "      -0.01780328225904071,\n",
      "      0.018244231845692013,\n",
      "      0.01848298983827379,\n",
      "      -0.01850307150716135\n",
      "    ]\n",
      "  ],\n",
      "  biasGradient: [\n",
      "    -0.00047255239929697504,\n",
      "    0.036236983543513485,\n",
      "    0.03629171323495291,\n",
      "    0.10853612322015335\n",
      "  ],\n",
      "  xGradient: [\n",
      "    [\n",
      "      -0.2883057747728355,\n",
      "      -0.14311099848483763,\n",
      "      -0.14650703663431658,\n",
      "      -0.00021083256611104106,\n",
      "      -0.14590664549574361,\n",
      "      -0.001396842609231952,\n",
      "      -0.005504911083759861,\n",
      "      0.14046970811399107,\n",
      "      -0.14141565920920618,\n",
      "      0.005732114643605346\n",
      "    ],\n",
      "    [\n",
      "      -0.14219853816920913,\n",
      "      -0.28910127257515944,\n",
      "      0.0008471524710994272,\n",
      "      -0.14659551957929098,\n",
      "      0.0054641132507455975,\n",
      "      -0.14293723473972797,\n",
      "      0.14777560814455665,\n",
      "      0.0004966549913069246,\n",
      "      -0.0007604339224881185,\n",
      "      -0.1472456109723722\n",
      "    ],\n",
      "    [\n",
      "      -0.14486417803245094,\n",
      "      0.00002576194008006849,\n",
      "      -0.2871956109995748,\n",
      "      -0.1398505772823005,\n",
      "      -0.0017679196757173915,\n",
      "      0.14406790250256957,\n",
      "      -0.14307064833783453,\n",
      "      0.002185275437296852,\n",
      "      -0.0034288652890533677,\n",
      "      0.14303163459741405\n",
      "    ],\n",
      "    [\n",
      "      -0.002878333997704041,\n",
      "      -0.14404200996867983,\n",
      "      -0.1495868721519825,\n",
      "      -0.2898018776715455,\n",
      "      0.1440886245940063,\n",
      "      0.0031836028327663912,\n",
      "      -0.0008427677293622177,\n",
      "      -0.1427177865612933,\n",
      "      0.14213414409677552,\n",
      "      0.001071740892161513\n",
      "    ],\n",
      "    [\n",
      "      -0.14705292765306932,\n",
      "      -0.004765288731107542,\n",
      "      0.0006357613818990387,\n",
      "      0.14429917777627804,\n",
      "      -0.2888170856306221,\n",
      "      -0.14472989807815856,\n",
      "      -0.14145117583960154,\n",
      "      0.003290832039077471,\n",
      "      -0.002983953483291793,\n",
      "      0.14064796494204018\n",
      "    ],\n",
      "    [\n",
      "      0.0020441835113710755,\n",
      "      -0.14505325385178902,\n",
      "      0.14411404848982137,\n",
      "      -0.0031215444842176004,\n",
      "      -0.1447590053497746,\n",
      "      -0.29067080920273825,\n",
      "      -0.0022129987888044045,\n",
      "      -0.14789911836742614,\n",
      "      0.14891207600622852,\n",
      "      0.0016484821569454494\n",
      "    ],\n",
      "    [\n",
      "      0.002048665616037476,\n",
      "      0.14123066675843737,\n",
      "      -0.14432094561169728,\n",
      "      -0.002323116006818532,\n",
      "      -0.14362611688918883,\n",
      "      -0.0008780544886705377,\n",
      "      -0.2877516342669661,\n",
      "      -0.14648945898282373,\n",
      "      0.1465098701954991,\n",
      "      0.2866460717816816\n",
      "    ],\n",
      "    [\n",
      "      0.14528086605404228,\n",
      "      -0.0035193269997041976,\n",
      "      0.0016028004025094023,\n",
      "      -0.1459440778479237,\n",
      "      -0.001945028808546162,\n",
      "      -0.14787994661773035,\n",
      "      -0.14267632569534544,\n",
      "      -0.290452362220007,\n",
      "      0.29117028406428364,\n",
      "      0.14183198921080917\n",
      "    ],\n",
      "    [\n",
      "      -0.14153897326812087,\n",
      "      0.004526025489865609,\n",
      "      0.0032959676994635256,\n",
      "      0.14808524500828973,\n",
      "      0.0007532882400407281,\n",
      "      0.14397660838566842,\n",
      "      0.14265291218263046,\n",
      "      0.2877085521229711,\n",
      "      -0.2883963811962639,\n",
      "      -0.14182104834592257\n",
      "    ],\n",
      "    [\n",
      "      -0.0030600216300350896,\n",
      "      -0.14324042176684965,\n",
      "      0.1444837683381332,\n",
      "      0.0014523109267043366,\n",
      "      0.14687319565496998,\n",
      "      0.0030620692350175893,\n",
      "      0.2921361814921646,\n",
      "      0.14983367181555118,\n",
      "      -0.14986694543014803,\n",
      "      -0.2910080643691546\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "linearNoBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "strategic-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "export {accuracy,Sigmoid,MSE,BinaryCrossEntropyLoss,CrossEntropyLoss,ReLU,Linear,Embedding,Learner}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "jslab"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "text/javascript",
   "name": "javascript",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
