{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "//default_exp nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-restaurant",
   "metadata": {},
   "source": [
    "# nn\n",
    "\n",
    "> A few modules that can be used to build neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "marine-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Imports we need in nn.module.js\n",
    "*/\n",
    "import {exp,shape,transpose,dotProduct,randn,zeros,argmax,mean,round} from './src/util.module.js';\n",
    "import {matrixSum1d,matrixSum2d,matrixSubtract1d,matrixSubtract2d,matrixMultiply1d,matrixMultiply2d} from './src/util.module.js';\n",
    "import {head,tail,parseCsv,IRIS_CLASS_MAP,IrisRowHandler,shuffle,split,batches} from './src/data.module.js';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enormous-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Imports we need for testing\n",
    "import {testEq} from './src/testutil.module.js'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compliant-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "yTrue can be either 2d (one-hot encoded targets) or 1d (array of class IDs).\n",
    "*/\n",
    "function accuracy(yPred2d,yTrue) {\n",
    "    const yPredShape=shape(yPred2d);\n",
    "    const yTrueShape=shape(yTrue);\n",
    "    if (yPredShape[0] != yTrueShape[0]) {\n",
    "        throw `Expected yPred2d.length ${yPredShape[0]} to equal yTrue.length ${yTrueShape[0]}`;\n",
    "    }\n",
    "    if (yTrueShape.length == 2 && yPredShape[1] != yTrueShape[1]) {\n",
    "        throw `Expected shape(yPred2d)[1] ${yPredShape[1]} to equal shape(yTrue)[1] ${yTrueShape[1]}`;\n",
    "    }\n",
    "    let correctCount=0;\n",
    "    for (let i=0; i<yPred2d.length; i++) {\n",
    "        let p = argmax(yPred2d[i]);\n",
    "        let t = (yTrueShape.length == 2) ? argmax(yTrue[i]) : yTrue[i];\n",
    "        if (p == t) {\n",
    "            correctCount++;\n",
    "        }\n",
    "    }\n",
    "    return correctCount/yPredShape[0];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recovered-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "let yPred=[[0,.1],[0,.9],[0,.33],[0,1],[0,1],[0,1],[0,1],[0,1],[1,0]];\n",
    "let yTrue=[[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[1,0]];\n",
    "testEq(1.0, accuracy(yPred,yTrue));\n",
    "yPred[0][0]=.8;\n",
    "testEq(8/9, accuracy(yPred,yTrue));\n",
    "yPred.map(a=>a[0]=1.1); // accuracy doesn't care if we're not within 0 and 1\n",
    "testEq(1/9, accuracy(yPred,yTrue));\n",
    "// test with class IDs\n",
    "testEq(1/9, accuracy(yPred,[1,1,1,1,1,1,1,1,0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daily-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class MSE {\n",
    "    forward(yPred2d,yTrue2d) {\n",
    "        this.error=matrixSubtract2d(yPred2d,yTrue2d);\n",
    "        return mean(this.error.map(row=>row.map(elem=>elem**2)));\n",
    "    }\n",
    "    backward() {\n",
    "        this.grad=matrixMultiply2d(this.error, 2/this.error.length);\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intelligent-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "let mse=new MSE();\n",
    "let mseValue=mse.forward(\n",
    "    [[-0.1684, -1.0158, -1.3667,  1.4327],\n",
    "    [ 0.0245, -0.6284, -2.5182,  2.2007],\n",
    "    [-1.8774, -0.0352, -0.5946,  0.4272]],\n",
    "    [[-0.3516,  0.5787,  0.8858,  0.9198],\n",
    "    [ 0.1892, -0.6473,  2.1278,  0.1345],\n",
    "    [ 2.2919, -0.9939, -0.3137, -0.4314]]);\n",
    "testEq(4.409, Math.round(mseValue*1000)/1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-shakespeare",
   "metadata": {},
   "source": [
    "## cross entropy: negative log likelyhood of log softmax\n",
    "\n",
    "The following is taken from https://github.com/fastai/course-v3/blob/master/nbs/dl2/03_minibatch_training.ipynb\n",
    "```\n",
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()\n",
    "\n",
    "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)\n",
    "\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "twenty-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Takes a 2d array and returns a 1d array of the log of the sum of the exp for each row.\n",
    "*/\n",
    "function logsumexp(x) {\n",
    "    const m = x.map(a => Math.max(...a));\n",
    "    let temp = x.map((row,i) => row.map(e => e-m[i])); // x-m[:,None]\n",
    "    temp = temp.map(row => row.map(e => exp(e)));      // .exp()\n",
    "    temp = temp.map(row => row.reduce((a,b) => a+b))   // .sum(-1)\n",
    "    temp = temp.map(a => Math.log(a));                 // .log()\n",
    "    return matrixSum1d(m, temp);                       // return m + ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "provincial-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "let testData=[[1.6392130817141863, 0.12928212984246149],\n",
    "              [0.000843200027605633, -0.12680858189363003],\n",
    "              [-0.9898354893794594, -1.5028466126461082]]\n",
    "testEq([1.8388, 0.6322, -0.5207], round(logsumexp(testData),4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indie-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Takes a 2d array and returns a 2d array of log softmax for each element.\n",
    "*/\n",
    "function log_softmax(x) {\n",
    "    const _logsumexp = logsumexp(x);\n",
    "    return x.map((row,i) => row.map(e => e-_logsumexp[i]));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "raising-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEq([[-0.1996089581238054, -1.7095399099955302],\n",
    "        [-0.6313567803288485, -0.7590085622500842],\n",
    "        [-0.4691846265662769, -0.9821957498329257]], log_softmax(testData));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "angry-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Takes a 2d input (log softmax predictions) and a 1d array of target class IDs and returns the negative log likelihood.\n",
    "*/\n",
    "function nll(input, target) {\n",
    "    return -mean(input.map((row,i) => row[target[i]]));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "residential-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEq(-0.2167, round(nll(testData,[0,0,0]),4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-rugby",
   "metadata": {},
   "source": [
    "`CrossEntropyLoss` uses an approach borrowed from https://beckernick.github.io/logistic-regression-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "simple-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Cross entropy with softmax.\n",
    "yTrue1d is an array of target class IDs - not a 2d array of 1 hot encoded targets.\n",
    "*/\n",
    "class CrossEntropyLoss {\n",
    "    softmax1d(a) {\n",
    "        const maxValue=Math.max(...a); // normalize values for numerical stability (log sum exp)\n",
    "        const temp=a.map(e => exp(e-maxValue));\n",
    "        const sum=temp.reduce((a,b)=>a+b);\n",
    "        return temp.map(e=>e/sum);\n",
    "    }\n",
    "        \n",
    "    forward(yPred2d,yTrue1d) {\n",
    "        this.yPred2d=yPred2d.map(yPred1d => this.softmax1d(yPred1d));\n",
    "        this.yTrue1d=yTrue1d;\n",
    "        const temp=this.yPred2d.map((yPred1d,i) => Math.log(yPred1d[yTrue1d[i]])); // TODO: add tiny value to avoid log(0)\n",
    "        return -temp.reduce((a,b) => a+b) / temp.length;\n",
    "    }\n",
    "    \n",
    "    backward() {\n",
    "        const yTrue1d=this.yTrue1d;\n",
    "        this.grad=this.yPred2d.map(yPred1d => [...yPred1d]); // copy preds\n",
    "        this.grad.forEach((yPred1d,i)=>yPred1d[yTrue1d[i]]-=1);\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coated-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "// show that both ways of calculating cross entropy loss give the same values\n",
    "let lossFn = new CrossEntropyLoss()\n",
    "testEq(round(nll(log_softmax(testData),[0,0,0]),4), round(lossFn.forward(testData,[0,0,0]),4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suitable-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class BinaryCrossEntropyLoss {\n",
    "    _forward1d(yPred1d,yTrue1d) {\n",
    "        const temp=yPred1d.map((yPred,i) => Math.log((yTrue1d[i]==1.) ? yPred : 1-yPred));\n",
    "        return -temp.reduce((a,b) => a+b) / temp.length;\n",
    "    }\n",
    "    forward(yPred2d,yTrue2d) {\n",
    "        this.yPred2d=yPred2d;\n",
    "        this.yTrue2d=yTrue2d;\n",
    "        const lossValue1d=yPred2d.map((yPred1d,i) => this._forward1d(yPred1d,yTrue2d[i]));\n",
    "        return lossValue1d.reduce((a,b) => a+b) / lossValue1d.length;\n",
    "    }\n",
    "    _backward1d(yPred1d,yTrue1d) {\n",
    "        return yPred1d.map((yPred,i) => (yTrue1d[i]==1.) ? -1/yPred : 1/(1-yPred));\n",
    "    }\n",
    "    backward() {\n",
    "        const yTrue2d=this.yTrue2d;\n",
    "        this.grad=this.yPred2d.map((yPred1d,i) => this._backward1d(yPred1d,yTrue2d[i]));\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "covered-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Sigmoid {\n",
    "    forward(x2d) {\n",
    "        this.results=x2d.map(x1d => x1d.map(x => 1./(1.+exp(-x))));\n",
    "        return this.results;\n",
    "    }\n",
    "    backward(gradients) {\n",
    "        // `s * (1.-s)` calculates sigmoid grad, then we chain gradients passed in\n",
    "        this.grad=this.results.map((result,i) => result.map((s,j) => s * (1.-s) * gradients[i][j]));\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "passing-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class ReLU {\n",
    "    forward(x2d) {\n",
    "        this.gradMask=zeros(...shape(x2d));\n",
    "        return x2d.map((x1d,rowIndex) => x1d.map((x,colIndex) => {\n",
    "            if (x>0) {\n",
    "                this.gradMask[rowIndex][colIndex]=1;\n",
    "            }\n",
    "            return Math.max(0,x);\n",
    "        }));\n",
    "    }\n",
    "    backward(gradient) {\n",
    "        return matrixMultiply2d(this.gradMask,gradient);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "attempted-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "let relu = new ReLU();\n",
    "let data = [\n",
    "  [ -0.3132450550822199, 0.06746248970796562, 0.7502210053477679 ],\n",
    "  [ 0.32586239499711434, 0.276573231917191, 0.4718188033994297 ],\n",
    "  [ 0.3375259522729109, -1.4738907605515226, -0.11109898767917284 ],\n",
    "  [ -0.6095143988686595, 1.094470501593892, -0.4982351760328258 ],\n",
    "  [ 0.28664244098736347, -0.35879217465991975, -0.754257906608068 ]\n",
    "];\n",
    "testEq(relu.forward(data),relu.backward(data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imported-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Linear {\n",
    "    constructor(inputDim,numHidden=1,bias=true) {\n",
    "        this.inputDim=inputDim;\n",
    "        this.numHidden=numHidden;\n",
    "        // Kaiming Init\n",
    "        this.weights=matrixMultiply2d(randn(inputDim,numHidden), Math.sqrt(2.0/inputDim));\n",
    "        this.bias=zeros(numHidden)\n",
    "        this.updateBias=bias;\n",
    "    }\n",
    "    forward(x) {\n",
    "        this.x=x; // shape(bs,inputDim)\n",
    "        return matrixSum2d(dotProduct(x,this.weights), this.bias);\n",
    "    }\n",
    "    backward(gradient) { // gradient shape(bs,numHidden)\n",
    "        // weightsGradient/biasGradient need to be the same shape as weights/bias\n",
    "        this.weightsGradient=dotProduct(transpose(this.x), gradient);\n",
    "        // this.biasGradient=gradient.sum(axis=0)\n",
    "        this.biasGradient=transpose(gradient).map(col => col.reduce((a,b) => a+b));\n",
    "        this.xGradient=dotProduct(gradient,transpose(this.weights));\n",
    "        return this.xGradient;\n",
    "    }\n",
    "    update(lr) {\n",
    "        // gradient calculations in backward don't account for batch size, so we do it here\n",
    "        lr=lr/this.x.length; // TODO: change gradient calc to account for batch size - all XxxLoss classes\n",
    "        this.weights=matrixSubtract2d(this.weights,matrixMultiply2d(this.weightsGradient,lr));\n",
    "        if (this.updateBias) {\n",
    "            this.bias=matrixSubtract1d(this.bias,matrixMultiply1d(this.biasGradient,lr));\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accomplished-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Learner {\n",
    "    constructor(model, lossFn, data, metrics=[accuracy]) {\n",
    "        this.model=model;\n",
    "        this.lossFn=lossFn;\n",
    "        this.metrics=metrics;\n",
    "        const splitData=split(shuffle(data));\n",
    "        this.xTrain=splitData[0][0];\n",
    "        this.xValid=splitData[0][1];\n",
    "        this.yTrain=splitData[1][0];\n",
    "        this.yValid=splitData[1][1];\n",
    "        // shame that we can destructure into this. )o:\n",
    "//         [[this.xTrain,this.xValid],[this.yTrain,this.yValid]]=split(data);\n",
    "    }\n",
    "    forward(x) {\n",
    "        for (let i=0; i<this.model.length; i++) {\n",
    "            x=this.model[i].forward(x);\n",
    "        }\n",
    "        return x;\n",
    "    }\n",
    "    backward(gradients) {\n",
    "        for (let i=this.model.length-1; i>=0; i--) {\n",
    "            gradients=this.model[i].backward(gradients);\n",
    "        }\n",
    "        return gradients;\n",
    "    }\n",
    "    step(lr) {\n",
    "        this.model.forEach(m => {\n",
    "            if (typeof m.update=='function') {\n",
    "                m.update(lr);\n",
    "            }\n",
    "        });\n",
    "    }\n",
    "    validate(epoch) {\n",
    "        const preds=this.forward(this.xValid);\n",
    "        const lossValue=this.lossFn.forward(preds,this.yValid);\n",
    "        const metricValues=this.metrics.map(metric=>metric(preds,this.yValid));\n",
    "        console.log('epoch',epoch,'valid loss',lossValue,'metrics',metricValues);\n",
    "    }\n",
    "    fit(epochs, lr=0.1, bs=64) {\n",
    "        this.validate(-1); // Note: we use epoch -1 to indicate before training\n",
    "        for (let epoch=0; epoch<epochs; epoch++) {\n",
    "            batches([this.xTrain,this.yTrain]).forEach(batch => {\n",
    "                const [xb,yb]=batch;\n",
    "                const preds=this.forward(xb);\n",
    "                const lossValue=this.lossFn.forward(preds,yb);\n",
    "                this.lossFn.backward();\n",
    "                this.backward(this.lossFn.grad);\n",
    "                this.step(lr);\n",
    "            });\n",
    "            this.validate(epoch);\n",
    "        }\n",
    "    }\n",
    "    predict(x,y,yToLabelFn=(a=>a)) {\n",
    "        const preds=this.forward(x);\n",
    "        return preds.map((pred,rowIndex) => {\n",
    "            const row=[pred,yToLabelFn(pred)];\n",
    "            if (y!=null) {\n",
    "                row.push(yToLabelFn(y[rowIndex]));\n",
    "            }\n",
    "            return row;\n",
    "        });\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-compilation",
   "metadata": {},
   "source": [
    "## Train a linear model to classify iris flowers\n",
    "\n",
    "Note: we use `BinaryCrossEntropyLoss` here just as an example. README.md and index.ipynb shows how to train with `CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "agreed-publication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -1 valid loss 0.7210415659408119 metrics [ 0.3333333333333333 ]\n",
      "epoch 0 valid loss 0.681603308853917 metrics [ 0.43333333333333335 ]\n",
      "epoch 1 valid loss 0.647636678668952 metrics [ 0.43333333333333335 ]\n",
      "epoch 2 valid loss 0.6187155608522726 metrics [ 0.5666666666666667 ]\n",
      "epoch 3 valid loss 0.5937510902428557 metrics [ 0.5666666666666667 ]\n",
      "epoch 4 valid loss 0.5725834754551206 metrics [ 0.5666666666666667 ]\n",
      "epoch 5 valid loss 0.5547588942571242 metrics [ 0.5666666666666667 ]\n",
      "epoch 6 valid loss 0.5392094565081945 metrics [ 0.5666666666666667 ]\n",
      "epoch 7 valid loss 0.5257326467000477 metrics [ 0.6333333333333333 ]\n",
      "epoch 8 valid loss 0.5138858140493918 metrics [ 0.6666666666666666 ]\n",
      "epoch 9 valid loss 0.5031579255606787 metrics [ 0.6666666666666666 ]\n",
      "epoch 10 valid loss 0.49356252138201095 metrics [ 0.6666666666666666 ]\n",
      "epoch 11 valid loss 0.4847578209911884 metrics [ 0.6666666666666666 ]\n",
      "epoch 12 valid loss 0.4767924295313482 metrics [ 0.6666666666666666 ]\n",
      "epoch 13 valid loss 0.4693622669311455 metrics [ 0.6666666666666666 ]\n",
      "epoch 14 valid loss 0.4625643179079832 metrics [ 0.6666666666666666 ]\n",
      "epoch 15 valid loss 0.4560917365147954 metrics [ 0.6666666666666666 ]\n",
      "epoch 16 valid loss 0.45017978512196943 metrics [ 0.6666666666666666 ]\n",
      "epoch 17 valid loss 0.4445588579806406 metrics [ 0.6666666666666666 ]\n",
      "epoch 18 valid loss 0.4394291530750062 metrics [ 0.6666666666666666 ]\n",
      "epoch 19 valid loss 0.43444197700123827 metrics [ 0.6666666666666666 ]\n",
      "epoch 20 valid loss 0.42976623811019893 metrics [ 0.7 ]\n",
      "epoch 21 valid loss 0.4252334746503537 metrics [ 0.7 ]\n",
      "epoch 22 valid loss 0.42087788519729846 metrics [ 0.7 ]\n",
      "epoch 23 valid loss 0.4167700304931366 metrics [ 0.7 ]\n",
      "epoch 24 valid loss 0.4128194364383735 metrics [ 0.7 ]\n"
     ]
    }
   ],
   "source": [
    "let stringData=require('fs').readFileSync('data/iris.data').toString();\n",
    "let data=parseCsv(stringData, new IrisRowHandler()).result;\n",
    "let lossFn=new BinaryCrossEntropyLoss();\n",
    "let model=[new Linear(4,3), new Sigmoid()];\n",
    "let learn=new Learner(model, lossFn, data);\n",
    "learn.fit(25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-cleaner",
   "metadata": {},
   "source": [
    "## Train a neural net to classify iris flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "disabled-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -1 valid loss 0.9544850777153755 metrics [ 0.3333333333333333 ]\n",
      "epoch 0 valid loss 0.4772857260011183 metrics [ 0.6666666666666666 ]\n",
      "epoch 1 valid loss 0.3785130032647902 metrics [ 0.7 ]\n",
      "epoch 2 valid loss 0.33558066956184474 metrics [ 0.7666666666666667 ]\n",
      "epoch 3 valid loss 0.31139052989210747 metrics [ 0.7666666666666667 ]\n",
      "epoch 4 valid loss 0.2937689742464834 metrics [ 0.8 ]\n",
      "epoch 5 valid loss 0.2806396850531637 metrics [ 0.8 ]\n",
      "epoch 6 valid loss 0.27192462472494827 metrics [ 0.8 ]\n",
      "epoch 7 valid loss 0.26450894052831625 metrics [ 0.8 ]\n",
      "epoch 8 valid loss 0.25786153151757457 metrics [ 0.8 ]\n",
      "epoch 9 valid loss 0.2520059933499623 metrics [ 0.8 ]\n",
      "epoch 10 valid loss 0.24484250251669143 metrics [ 0.8 ]\n",
      "epoch 11 valid loss 0.24043759144420304 metrics [ 0.8 ]\n",
      "epoch 12 valid loss 0.23505814502789057 metrics [ 0.8 ]\n",
      "epoch 13 valid loss 0.23142922230072563 metrics [ 0.8 ]\n",
      "epoch 14 valid loss 0.22798985768489013 metrics [ 0.8 ]\n",
      "epoch 15 valid loss 0.224103129512089 metrics [ 0.8 ]\n",
      "epoch 16 valid loss 0.21737167884490471 metrics [ 0.8 ]\n",
      "epoch 17 valid loss 0.21529033281728388 metrics [ 0.8 ]\n",
      "epoch 18 valid loss 0.21100099601656927 metrics [ 0.8 ]\n",
      "epoch 19 valid loss 0.2077319627559277 metrics [ 0.8 ]\n",
      "epoch 20 valid loss 0.20443818797094307 metrics [ 0.8 ]\n",
      "epoch 21 valid loss 0.20121356639797808 metrics [ 0.8 ]\n",
      "epoch 22 valid loss 0.19879356207770213 metrics [ 0.8 ]\n",
      "epoch 23 valid loss 0.1955799144971639 metrics [ 0.8 ]\n",
      "epoch 24 valid loss 0.19363424201035084 metrics [ 0.8 ]\n"
     ]
    }
   ],
   "source": [
    "let model=[new Linear(4,50), new ReLU(), new Linear(50,3), new Sigmoid()];\n",
    "let learn=new Learner(model, lossFn, data);\n",
    "learn.fit(25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-coordination",
   "metadata": {},
   "source": [
    "### Look at some predictions \n",
    "\n",
    "We use the lambda ```(y=>`${argmax(y)}: ${IRIS_CLASS_MAP[argmax(y)]}`)``` to convert predictions like `[0.000, 0.183, 0.843]` to readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sensitive-checkout",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [\n",
      "  [ 0.000003083883493382887, 0.03980108307300796, 0.9824464784167263 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "1 [\n",
      "  [ 0.005712331123562325, 0.944045080024074, 0.09338924667776642 ],\n",
      "  '1: Iris-versicolor',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "2 [\n",
      "  [ 0.015015240144698608, 0.25511576053535273, 0.7727902143792333 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "3 [\n",
      "  [ 0.004965843084547645, 0.4709298195635195, 0.6636975377120846 ],\n",
      "  '2: Iris-virginica',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "4 [\n",
      "  [ 0.00011758612246877341, 0.09335210891096556, 0.9162445951186915 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "5 [\n",
      "  [ 0.0003141267416208043, 0.03246172473372288, 0.7861595658934284 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "6 [\n",
      "  [ 0.01025025257603669, 0.36465488141600955, 0.5899431992417702 ],\n",
      "  '2: Iris-virginica',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "7 [\n",
      "  [ 0.9691683493445117, 0.04231205232544927, 0.006490749828945177 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "8 [\n",
      "  [ 0.9920779134719121, 0.015680672698955428, 0.004180108834395382 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "9 [\n",
      "  [ 0.002650282874706003, 0.13388087913526525, 0.8885899940072658 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "// head(learn.predict(learn.xValid, learn.yValid)); run this to see \"raw\" targets\n",
    "head(learn.predict(learn.xValid, learn.yValid, (y=>`${argmax(y)}: ${IRIS_CLASS_MAP[argmax(y)]}`)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-liabilities",
   "metadata": {},
   "source": [
    "Show how we could train a linear layer without `Learner` - this is not a proper training loop, we just;\n",
    "- forward pass\n",
    "- print training loss\n",
    "- backward pass\n",
    "- update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "western-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape(x) [ 150, 4 ] shape(y) [ 150, 3 ]\n",
      "epoch 0 loss_value 0.7456237404624781\n",
      "epoch 1 loss_value 0.7083050326952027\n",
      "epoch 2 loss_value 0.6750960154499097\n",
      "epoch 3 loss_value 0.6456738843500313\n",
      "epoch 4 loss_value 0.6196645232383754\n",
      "epoch 5 loss_value 0.5966752272399144\n",
      "epoch 6 loss_value 0.5763212925279265\n",
      "epoch 7 loss_value 0.5582443237905863\n",
      "epoch 8 loss_value 0.5421225072946342\n",
      "epoch 9 loss_value 0.5276744683398552\n"
     ]
    }
   ],
   "source": [
    "let data=parseCsv(stringData, new IrisRowHandler()).result;\n",
    "let x=data[0],y=data[1];\n",
    "console.log('shape(x)',shape(x), 'shape(y)',shape(y));\n",
    "let loss_fn=new BinaryCrossEntropyLoss()\n",
    "let sig=new Sigmoid()\n",
    "let lin=new Linear(4,3);\n",
    "for (let epoch = 0; epoch < 10; epoch++) {\n",
    "    let y_pred=sig.forward(lin.forward(x));\n",
    "    let loss_value=loss_fn.forward(y_pred,y);\n",
    "    console.log('epoch',epoch,'loss_value',loss_value);\n",
    "    loss_fn.backward();\n",
    "    sig.backward(loss_fn.grad);\n",
    "    lin.backward(sig.grad);\n",
    "    lin.update(.1);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-november",
   "metadata": {},
   "source": [
    "## Can we teach a linear layer to convert one hot encoded integers to their bitwise representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "regulated-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "let x=[\n",
    "    [1,0,0,0,0,0,0,0,0,0],\n",
    "    [0,1,0,0,0,0,0,0,0,0],\n",
    "    [0,0,1,0,0,0,0,0,0,0],\n",
    "    [0,0,0,1,0,0,0,0,0,0],\n",
    "    [0,0,0,0,1,0,0,0,0,0],\n",
    "    [0,0,0,0,0,1,0,0,0,0],\n",
    "    [0,0,0,0,0,0,1,0,0,0],\n",
    "    [0,0,0,0,0,0,0,1,0,0],\n",
    "    [0,0,0,0,0,0,0,0,1,0],\n",
    "    [0,0,0,0,0,0,0,0,0,1]\n",
    "];\n",
    "let y=[\n",
    "    [0,0,0,0],\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [1,1,0,0],\n",
    "    [0,0,1,0],\n",
    "    [1,0,1,0],\n",
    "    [0,1,1,0],\n",
    "    [1,1,1,0],\n",
    "    [0,0,0,1],\n",
    "    [1,0,0,1]\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-fight",
   "metadata": {},
   "source": [
    "`x` is an identity matrix, so ... `x.y` is `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sixth-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEq(y,dotProduct(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-count",
   "metadata": {},
   "source": [
    "so ... will `y` make the perfect weights (if bias is zero)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adult-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss_value 0.018167369338112204\n",
      "[\n",
      "  [\n",
      "    0.018419955736153345,\n",
      "    0.017912951871688565,\n",
      "    0.018235536054458837,\n",
      "    0.017601739536903506\n",
      "  ],\n",
      "  [\n",
      "    0.9816460419899544,\n",
      "    0.01851251520639118,\n",
      "    0.01819493931774505,\n",
      "    0.018482264267305634\n",
      "  ],\n",
      "  [\n",
      "    0.017706703674205408,\n",
      "    0.9818826400504213,\n",
      "    0.01756896075146458,\n",
      "    0.01802703779365143\n",
      "  ],\n",
      "  [\n",
      "    0.9821918265400942,\n",
      "    0.9815438220201382,\n",
      "    0.018214569680693155,\n",
      "    0.017457467681792623\n",
      "  ],\n",
      "  [\n",
      "    0.017758723795838843,\n",
      "    0.017940734670875647,\n",
      "    0.982115044156826,\n",
      "    0.017544494277273073\n",
      "  ],\n",
      "  [\n",
      "    0.9822971831135902,\n",
      "    0.018141939952034763,\n",
      "    0.9819953931672954,\n",
      "    0.018088397873372603\n",
      "  ],\n",
      "  [\n",
      "    0.017744144856964045,\n",
      "    0.9818603281264469,\n",
      "    0.9817086094802139,\n",
      "    0.018077385207505466\n",
      "  ],\n",
      "  [\n",
      "    0.9825125112010706,\n",
      "    0.9824859780833001,\n",
      "    0.982205941346248,\n",
      "    0.018514279512330027\n",
      "  ],\n",
      "  [\n",
      "    0.01850733499318103,\n",
      "    0.018464845626273582,\n",
      "    0.01750969179256001,\n",
      "    0.9822861804223016\n",
      "  ],\n",
      "  [\n",
      "    0.9815203866006909,\n",
      "    0.017447250320788112,\n",
      "    0.018050334609328544,\n",
      "    0.9817412092426392\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "let loss_fn=new BinaryCrossEntropyLoss()\n",
    "let sig=new Sigmoid()\n",
    "let linearNoBias=new Linear(10,4,false);\n",
    "let y_pred=null;\n",
    "for (let epoch = 0; epoch<10; epoch++) {\n",
    "    y_pred=sig.forward(linearNoBias.forward(x));\n",
    "    const loss_value=loss_fn.forward(y_pred,y);\n",
    "    if (epoch%10==9) {\n",
    "        console.log('epoch',epoch,'loss_value',loss_value);\n",
    "    }\n",
    "    loss_fn.backward();\n",
    "    sig.backward(loss_fn.grad);\n",
    "    linearNoBias.backward(sig.grad);\n",
    "    linearNoBias.update(50);\n",
    "}\n",
    "console.log(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-skirt",
   "metadata": {},
   "source": [
    "dump our linear layer to output - so we can look at the learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "statewide-cholesterol",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear {\n",
      "  inputDim: 10,\n",
      "  numHidden: 4,\n",
      "  weights: [\n",
      "    [\n",
      "      -4.067828714273833,\n",
      "      -4.093720688051305,\n",
      "      -4.077156885603839,\n",
      "      -4.1100077498905\n",
      "    ],\n",
      "    [\n",
      "      4.071155340777657,\n",
      "      -4.0631848375597395,\n",
      "      -4.079223976740948,\n",
      "      -4.06469982092297\n",
      "    ],\n",
      "    [\n",
      "      -4.104480148029213,\n",
      "      4.083187997957094,\n",
      "      -4.111741204562182,\n",
      "      -4.0878262330286645\n",
      "    ],\n",
      "    [\n",
      "      4.099169964239447,\n",
      "      4.066008386333582,\n",
      "      -4.078223824418697,\n",
      "      -4.117663466620966\n",
      "    ],\n",
      "    [\n",
      "      -4.101753719297217,\n",
      "      -4.092281524200758,\n",
      "      4.0951733298404545,\n",
      "      -4.113037343010202\n",
      "    ],\n",
      "    [\n",
      "      4.104684204422819,\n",
      "      -4.081930073664264,\n",
      "      4.088981990930716,\n",
      "      -4.0846725441970815\n",
      "    ],\n",
      "    [\n",
      "      -4.102516949365545,\n",
      "      4.082046069590711,\n",
      "      4.074320999484547,\n",
      "      -4.085237706586823\n",
      "    ],\n",
      "    [\n",
      "      4.116064822231172,\n",
      "      4.114654369073136,\n",
      "      4.099906677791539,\n",
      "      -4.063096562629115\n",
      "    ],\n",
      "    [\n",
      "      -4.0634440757839005,\n",
      "      -4.065573370267513,\n",
      "      -4.114884393890352,\n",
      "      4.104106687837266\n",
      "    ],\n",
      "    [\n",
      "      4.06483270531507,\n",
      "      -4.118208221654773,\n",
      "      -4.086627500327766,\n",
      "      4.075975043643652\n",
      "    ]\n",
      "  ],\n",
      "  bias: [ 0, 0, 0, 0 ],\n",
      "  updateBias: false,\n",
      "  x: [\n",
      "    [\n",
      "      1, 0, 0, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 1, 0, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 1, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 1, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 1,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      1, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 1, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 1, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 0, 1, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 0, 0, 1\n",
      "    ]\n",
      "  ],\n",
      "  weightsGradient: [\n",
      "    [\n",
      "      0.018419955736153345,\n",
      "      0.017912951871688565,\n",
      "      0.018235536054458837,\n",
      "      0.01760173953690351\n",
      "    ],\n",
      "    [\n",
      "      -0.01835395801004558,\n",
      "      0.01851251520639118,\n",
      "      0.018194939317745053,\n",
      "      0.01848226426730563\n",
      "    ],\n",
      "    [\n",
      "      0.017706703674205408,\n",
      "      -0.01811735994957875,\n",
      "      0.01756896075146458,\n",
      "      0.018027037793651432\n",
      "    ],\n",
      "    [\n",
      "      -0.01780817345990582,\n",
      "      -0.018456177979861765,\n",
      "      0.018214569680693155,\n",
      "      0.017457467681792623\n",
      "    ],\n",
      "    [\n",
      "      0.017758723795838843,\n",
      "      0.017940734670875647,\n",
      "      -0.017884955843173955,\n",
      "      0.017544494277273073\n",
      "    ],\n",
      "    [\n",
      "      -0.017702816886409845,\n",
      "      0.018141939952034763,\n",
      "      -0.01800460683270455,\n",
      "      0.018088397873372603\n",
      "    ],\n",
      "    [\n",
      "      0.017744144856964045,\n",
      "      -0.018139671873553143,\n",
      "      -0.01829139051978612,\n",
      "      0.018077385207505466\n",
      "    ],\n",
      "    [\n",
      "      -0.017487488798929363,\n",
      "      -0.01751402191669993,\n",
      "      -0.017794058653752057,\n",
      "      0.018514279512330027\n",
      "    ],\n",
      "    [\n",
      "      0.018507334993181027,\n",
      "      0.018464845626273582,\n",
      "      0.017509691792560015,\n",
      "      -0.017713819577698353\n",
      "    ],\n",
      "    [\n",
      "      -0.018479613399309147,\n",
      "      0.017447250320788112,\n",
      "      0.018050334609328544,\n",
      "      -0.01825879075736081\n",
      "    ]\n",
      "  ],\n",
      "  biasGradient: [\n",
      "    0.0003048125017429161,\n",
      "    0.036193005928358266,\n",
      "    0.03579902035683351,\n",
      "    0.10782045581507521\n",
      "  ],\n",
      "  xGradient: [\n",
      "    [\n",
      "      -0.2884396506957291,\n",
      "      -0.1404725108474581,\n",
      "      -0.14619851045353777,\n",
      "      0.0013981236344886988,\n",
      "      -0.14342210362804142,\n",
      "      0.005100891732011004,\n",
      "      -0.00012379136456225348,\n",
      "      0.1495975297799123,\n",
      "      -0.14707674209860935,\n",
      "      -0.0017732734973242986\n",
      "    ],\n",
      "    [\n",
      "      -0.1480169347040145,\n",
      "      -0.29252651973094745,\n",
      "      0.0005206730373313317,\n",
      "      -0.14707449711384246,\n",
      "      -0.0019566635670404953,\n",
      "      -0.1486617547138548,\n",
      "      0.14619301436485596,\n",
      "      0.00020464959591076637,\n",
      "      0.00026612649836856017,\n",
      "      -0.146601215186065\n",
      "    ],\n",
      "    [\n",
      "      -0.14038656103191352,\n",
      "      0.0007210035086715055,\n",
      "      -0.2862067754581759,\n",
      "      -0.14369312557329766,\n",
      "      -0.0007278159586962679,\n",
      "      0.14167691816166605,\n",
      "      -0.145424327398992,\n",
      "      -0.0027352471712446813,\n",
      "      0.0033052451355715523,\n",
      "      0.14498911967882266\n",
      "    ],\n",
      "    [\n",
      "      0.0018850705422903402,\n",
      "      -0.1395734195232327,\n",
      "      -0.1452545877139081,\n",
      "      -0.2877372967563857,\n",
      "      0.14802696056589254,\n",
      "      0.00525218518002879,\n",
      "      0.000619532005266557,\n",
      "      -0.14232491347819415,\n",
      "      0.14079052779984516,\n",
      "      0.0004247063859540018\n",
      "    ],\n",
      "    [\n",
      "      -0.14171624842727523,\n",
      "      0.0010707978185991174,\n",
      "      0.002141853569839716,\n",
      "      0.14310547391552977,\n",
      "      -0.2853389869230334,\n",
      "      -0.14188132933496359,\n",
      "      -0.14099317255149363,\n",
      "      0.0023958549199555867,\n",
      "      0.0006780452385101582,\n",
      "      0.13961099073990513\n",
      "    ],\n",
      "    [\n",
      "      -0.0032470857474234532,\n",
      "      -0.1425265989741865,\n",
      "      0.14366394545301042,\n",
      "      -0.00001541674858468456,\n",
      "      -0.146507253883208,\n",
      "      -0.28775491980803947,\n",
      "      -0.0005040615170955609,\n",
      "      -0.14229470354935406,\n",
      "      0.14335904093253338,\n",
      "      0.0005767380533735766\n",
      "    ],\n",
      "    [\n",
      "      0.0022900406093607217,\n",
      "      0.1437786143229088,\n",
      "      -0.14234915485775257,\n",
      "      -0.0008539275461870444,\n",
      "      -0.14463897504194112,\n",
      "      -0.0016888319610921937,\n",
      "      -0.2886916975161638,\n",
      "      -0.14670775594447655,\n",
      "      0.147869073745371,\n",
      "      0.28873985043639494\n",
      "    ],\n",
      "    [\n",
      "      0.13611672304321137,\n",
      "      -0.002624812901777379,\n",
      "      -0.0021106040079620636,\n",
      "      -0.14339494997750024,\n",
      "      -0.005526498312495631,\n",
      "      -0.14543842004447616,\n",
      "      -0.144546435168073,\n",
      "      -0.2858632681325361,\n",
      "      0.28503620842631594,\n",
      "      0.1460158705251819\n",
      "    ],\n",
      "    [\n",
      "      -0.14606457016440383,\n",
      "      0.0008622804598564376,\n",
      "      -0.00024451271903053184,\n",
      "      0.14917063819048534,\n",
      "      -0.006733055114574171,\n",
      "      0.14140495595977964,\n",
      "      0.13991773585722592,\n",
      "      0.2894820719224713,\n",
      "      -0.2885042648796095,\n",
      "      -0.14147132748426783\n",
      "    ],\n",
      "    [\n",
      "      0.005097003617307236,\n",
      "      -0.14227399654075062,\n",
      "      0.14423338150285003,\n",
      "      -0.00315463191238384,\n",
      "      0.1501264572216499,\n",
      "      0.001259275083700731,\n",
      "      0.2886446183793413,\n",
      "      0.1407098026817069,\n",
      "      -0.14195506060094076,\n",
      "      -0.2886298125292731\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "linearNoBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "export {accuracy,Sigmoid,MSE,BinaryCrossEntropyLoss,CrossEntropyLoss,ReLU,Linear,Learner}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "jslab"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "text/javascript",
   "name": "javascript",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
