{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinct-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "//default_exp nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-restaurant",
   "metadata": {},
   "source": [
    "# nn\n",
    "\n",
    "> A few modules that can be used to build neural nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "marine-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Imports we need in nn.module.js\n",
    "*/\n",
    "import {exp,shape,transpose,dotProduct,randn,zeros,argmax,mean} from './src/util.module.js';\n",
    "import {matrixSum1d,matrixSum2d,matrixSubtract1d,matrixSubtract2d,matrixMultiply1d,matrixMultiply2d} from './src/util.module.js';\n",
    "import {head,tail,parseCsv,IRIS_CLASS_MAP,IrisRowHandler,shuffle,split,batches} from './src/data.module.js';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enormous-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Imports we need for testing\n",
    "import {testEq} from './src/testutil.module.js'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compliant-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "yTrue can be either 2d (one-hot encoded targets) or 1d (array of class IDs).\n",
    "*/\n",
    "function accuracy(yPred2d,yTrue) {\n",
    "    const yPredShape=shape(yPred2d);\n",
    "    const yTrueShape=shape(yTrue);\n",
    "    if (yPredShape[0] != yTrueShape[0]) {\n",
    "        throw `Expected yPred2d.length ${yPredShape[0]} to equal yTrue.length ${yTrueShape[0]}`;\n",
    "    }\n",
    "    if (yTrueShape.length == 2 && yPredShape[1] != yTrueShape[1]) {\n",
    "        throw `Expected shape(yPred2d)[1] ${yPredShape[1]} to equal shape(yTrue)[1] ${yTrueShape[1]}`;\n",
    "    }\n",
    "    let correctCount=0;\n",
    "    for (let i=0; i<yPred2d.length; i++) {\n",
    "        let p = argmax(yPred2d[i]);\n",
    "        let t = (yTrueShape.length == 2) ? argmax(yTrue[i]) : yTrue[i];\n",
    "        if (p == t) {\n",
    "            correctCount++;\n",
    "        }\n",
    "    }\n",
    "    return correctCount/yPredShape[0];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recovered-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "let yPred=[[0,.1],[0,.9],[0,.33],[0,1],[0,1],[0,1],[0,1],[0,1],[1,0]];\n",
    "let yTrue=[[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[1,0]];\n",
    "testEq(1.0, accuracy(yPred,yTrue));\n",
    "yPred[0][0]=.8;\n",
    "testEq(8/9, accuracy(yPred,yTrue));\n",
    "yPred.map(a=>a[0]=1.1); // accuracy doesn't care if we're not within 0 and 1\n",
    "testEq(1/9, accuracy(yPred,yTrue));\n",
    "// test with class IDs\n",
    "testEq(1/9, accuracy(yPred,[1,1,1,1,1,1,1,1,0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daily-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class MSE {\n",
    "    forward(yPred2d,yTrue2d) {\n",
    "        this.error=matrixSubtract2d(yPred2d,yTrue2d);\n",
    "        return mean(this.error.map(row=>row.map(elem=>elem**2)));\n",
    "    }\n",
    "    backward() {\n",
    "        this.grad=matrixMultiply2d(this.error, 2/this.error.length);\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intelligent-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "let mse=new MSE();\n",
    "let mseValue=mse.forward(\n",
    "    [[-0.1684, -1.0158, -1.3667,  1.4327],\n",
    "    [ 0.0245, -0.6284, -2.5182,  2.2007],\n",
    "    [-1.8774, -0.0352, -0.5946,  0.4272]],\n",
    "    [[-0.3516,  0.5787,  0.8858,  0.9198],\n",
    "    [ 0.1892, -0.6473,  2.1278,  0.1345],\n",
    "    [ 2.2919, -0.9939, -0.3137, -0.4314]]);\n",
    "testEq(4.409, Math.round(mseValue*1000)/1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-shakespeare",
   "metadata": {},
   "source": [
    "cross entropy: negative log likelyhood of log softmax\n",
    "```\n",
    "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
    "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()\n",
    "\n",
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()\n",
    "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)\n",
    "\n",
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()\n",
    "```\n",
    "\n",
    "input==log softmax predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-davis",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "ce_loss_fn=nn.CrossEntropyLoss()\n",
    "nll_loss_fn=nn.NLLLoss()\n",
    "input=torch.randn(10,3,requires_grad=True)\n",
    "input\n",
    "target=torch.tensor(np.random.choice(3,10))\n",
    "target\n",
    "nn.NLLLoss(reduction='none')(input,target), nn.NLLLoss()(input,target)\n",
    "# input=torch.randn(10,3,requires_grad=True)\n",
    "input=torch.tensor(np.eye(3)[target],requires_grad=True)\n",
    "loss_value=nll_loss_fn( input,target)\n",
    "print(loss_value)\n",
    "loss_value.backward()\n",
    "input.grad\n",
    "tensor(-1., dtype=torch.float64, grad_fn=<NllLossBackward>)\n",
    "tensor([[ 0.0000, -0.1000,  0.0000],\n",
    "        [ 0.0000, -0.1000,  0.0000],\n",
    "        [ 0.0000,  0.0000, -0.1000],\n",
    "        [ 0.0000, -0.1000,  0.0000],\n",
    "        [-0.1000,  0.0000,  0.0000],\n",
    "        [-0.1000,  0.0000,  0.0000],\n",
    "        [ 0.0000,  0.0000, -0.1000],\n",
    "        [ 0.0000, -0.1000,  0.0000],\n",
    "        [ 0.0000,  0.0000, -0.1000],\n",
    "        [ 0.0000,  0.0000, -0.1000]], dtype=torch.float64)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "simple-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Cross entropy with softmax.\n",
    "yTrue1d is an array of target class IDs - not a 2d array of 2 hot encoded targets.\n",
    "*/\n",
    "class CrossEntropyLoss {\n",
    "    softmax1d(a) {\n",
    "        const maxValue=Math.max(...a); // normalize values for numerical stability (log sum exp)\n",
    "        const temp=a.map(e => exp(e-maxValue));\n",
    "        const sum=temp.reduce((a,b)=>a+b);\n",
    "        return temp.map(e=>e/sum);\n",
    "    }\n",
    "        \n",
    "    forward(yPred2d,yTrue1d) {\n",
    "        this.yPred2d=yPred2d.map(yPred1d => this.softmax1d(yPred1d));\n",
    "        this.yTrue1d=yTrue1d;\n",
    "        const temp=this.yPred2d.map((yPred1d,i) => Math.log(yPred1d[yTrue1d[i]])); // TODO: add tiny value to avoid log(0)\n",
    "        return -temp.reduce((a,b) => a+b) / temp.length;\n",
    "    }\n",
    "    \n",
    "    backward() {\n",
    "        const yTrue1d=this.yTrue1d;\n",
    "        this.grad=this.yPred2d.map(yPred1d => [...yPred1d]); // copy preds\n",
    "        this.grad.forEach((yPred1d,i)=>yPred1d[yTrue1d[i]]-=1);\n",
    "//         this.grad=matrixMultiply2d(this.grad,1/this.grad.length); // TODO: xxx\n",
    "        return this.grad; // TODO: mean for all loss functions\n",
    "        // output_error_signal = (output_probs - training_labels) / output_probs.shape[0]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "other-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9296404163515675\n"
     ]
    }
   ],
   "source": [
    "var input=\n",
    "        [[ 0.7168,  0.7141, -0.8293],\n",
    "        [-1.3728,  1.9252,  0.6447],\n",
    "        [-0.1829, -0.0563,  1.3041],\n",
    "        [-0.7842, -0.1915,  1.0120],\n",
    "        [-0.2175, -1.0389, -0.1599],\n",
    "        [ 0.3811,  0.2495, -1.8275],\n",
    "        [-0.8893, -0.6678,  0.7714],\n",
    "        [ 0.9122,  0.0140, -1.6649],\n",
    "        [-0.9544, -0.3054, -0.2324],\n",
    "        [-2.4975,  0.0240,  0.8549]];\n",
    "var target=[2, 2, 0, 2, 2, 2, 1, 2, 2, 0];\n",
    "let lossFn = new CrossEntropyLoss()\n",
    "lossFn.forward(input,target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suitable-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class BinaryCrossEntropyLoss {\n",
    "    _forward1d(yPred1d,yTrue1d) {\n",
    "        const temp=yPred1d.map((yPred,i) => Math.log((yTrue1d[i]==1.) ? yPred : 1-yPred));\n",
    "        return -temp.reduce((a,b) => a+b) / temp.length;\n",
    "    }\n",
    "    forward(yPred2d,yTrue2d) {\n",
    "        this.yPred2d=yPred2d;\n",
    "        this.yTrue2d=yTrue2d;\n",
    "        const lossValue1d=yPred2d.map((yPred1d,i) => this._forward1d(yPred1d,yTrue2d[i]));\n",
    "        return lossValue1d.reduce((a,b) => a+b) / lossValue1d.length;\n",
    "    }\n",
    "    _backward1d(yPred1d,yTrue1d) {\n",
    "        return yPred1d.map((yPred,i) => (yTrue1d[i]==1.) ? -1/yPred : 1/(1-yPred));\n",
    "    }\n",
    "    backward() {\n",
    "        const yTrue2d=this.yTrue2d;\n",
    "        this.grad=this.yPred2d.map((yPred1d,i) => this._backward1d(yPred1d,yTrue2d[i]));\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "covered-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Sigmoid {\n",
    "    forward(x2d) {\n",
    "        this.results=x2d.map(x1d => x1d.map(x => 1./(1.+exp(-x))));\n",
    "        return this.results;\n",
    "    }\n",
    "    backward(gradients) {\n",
    "        // `s * (1.-s)` calculates sigmoid grad, then we chain gradients passed in\n",
    "        this.grad=this.results.map((result,i) => result.map((s,j) => s * (1.-s) * gradients[i][j]));\n",
    "        return this.grad;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "passing-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class ReLU {\n",
    "    forward(x2d) {\n",
    "        this.gradMask=zeros(...shape(x2d));\n",
    "        return x2d.map((x1d,rowIndex) => x1d.map((x,colIndex) => {\n",
    "            if (x>0) {\n",
    "                this.gradMask[rowIndex][colIndex]=1;\n",
    "            }\n",
    "            return Math.max(0,x);\n",
    "        }));\n",
    "    }\n",
    "    backward(gradient) {\n",
    "        return matrixMultiply2d(this.gradMask,gradient);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "attempted-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "let relu = new ReLU();\n",
    "let data = [\n",
    "  [ -0.3132450550822199, 0.06746248970796562, 0.7502210053477679 ],\n",
    "  [ 0.32586239499711434, 0.276573231917191, 0.4718188033994297 ],\n",
    "  [ 0.3375259522729109, -1.4738907605515226, -0.11109898767917284 ],\n",
    "  [ -0.6095143988686595, 1.094470501593892, -0.4982351760328258 ],\n",
    "  [ 0.28664244098736347, -0.35879217465991975, -0.754257906608068 ]\n",
    "];\n",
    "testEq(relu.forward(data),relu.backward(data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "imported-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Linear {\n",
    "    constructor(inputDim,numHidden=1,bias=true) {\n",
    "        this.inputDim=inputDim;\n",
    "        this.numHidden=numHidden;\n",
    "        // Kaiming Init\n",
    "        this.weights=matrixMultiply2d(randn(inputDim,numHidden), Math.sqrt(2.0/inputDim));\n",
    "        this.bias=zeros(numHidden)\n",
    "        this.updateBias=bias;\n",
    "    }\n",
    "    forward(x) {\n",
    "        this.x=x; // shape(bs,inputDim)\n",
    "        return matrixSum2d(dotProduct(x,this.weights), this.bias);\n",
    "    }\n",
    "    backward(gradient) { // gradient shape(bs,numHidden)\n",
    "        // weightsGradient/biasGradient need to be the same shape as weights/bias\n",
    "        this.weightsGradient=dotProduct(transpose(this.x), gradient);\n",
    "        // this.biasGradient=gradient.sum(axis=0)\n",
    "        this.biasGradient=transpose(gradient).map(col => col.reduce((a,b) => a+b));\n",
    "        this.xGradient=dotProduct(gradient,transpose(this.weights));\n",
    "        return this.xGradient;\n",
    "    }\n",
    "    update(lr) {\n",
    "        // gradient calculations in backward don't account for batch size, so we do it here\n",
    "        lr=lr/this.x.length; // TODO: change gradient calc to account for batch size - all XxxLoss classes\n",
    "        this.weights=matrixSubtract2d(this.weights,matrixMultiply2d(this.weightsGradient,lr));\n",
    "        if (this.updateBias) {\n",
    "            this.bias=matrixSubtract1d(this.bias,matrixMultiply1d(this.biasGradient,lr));\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accomplished-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Learner {\n",
    "    constructor(model, lossFn, data, metrics=[accuracy]) {\n",
    "        this.model=model;\n",
    "        this.lossFn=lossFn;\n",
    "        this.metrics=metrics;\n",
    "        const splitData=split(shuffle(data));\n",
    "        this.xTrain=splitData[0][0];\n",
    "        this.xValid=splitData[0][1];\n",
    "        this.yTrain=splitData[1][0];\n",
    "        this.yValid=splitData[1][1];\n",
    "        // shame that we can destructure into this. )o:\n",
    "//         [[this.xTrain,this.xValid],[this.yTrain,this.yValid]]=split(data);\n",
    "    }\n",
    "    forward(x) {\n",
    "        for (let i=0; i<this.model.length; i++) {\n",
    "            x=this.model[i].forward(x);\n",
    "        }\n",
    "        return x;\n",
    "    }\n",
    "    backward(gradients) {\n",
    "        for (let i=this.model.length-1; i>=0; i--) {\n",
    "            gradients=this.model[i].backward(gradients);\n",
    "        }\n",
    "        return gradients;\n",
    "    }\n",
    "    step(lr) {\n",
    "        this.model.forEach(m => {\n",
    "            if (typeof m.update=='function') {\n",
    "                m.update(lr);\n",
    "            }\n",
    "        });\n",
    "    }\n",
    "    validate(epoch) {\n",
    "        const preds=this.forward(this.xValid);\n",
    "        const lossValue=this.lossFn.forward(preds,this.yValid);\n",
    "        const metricValues=this.metrics.map(metric=>metric(preds,this.yValid));\n",
    "        console.log('epoch',epoch,'valid loss',lossValue,'metrics',metricValues);\n",
    "    }\n",
    "    fit(epochs, lr=0.1, bs=64) {\n",
    "        this.validate(-1); // Note: we use epoch -1 to indicate before training\n",
    "        for (let epoch=0; epoch<epochs; epoch++) {\n",
    "            batches([this.xTrain,this.yTrain]).forEach(batch => {\n",
    "                const [xb,yb]=batch;\n",
    "                const preds=this.forward(xb);\n",
    "                const lossValue=this.lossFn.forward(preds,yb);\n",
    "                this.lossFn.backward();\n",
    "                this.backward(this.lossFn.grad);\n",
    "                this.step(lr);\n",
    "            });\n",
    "            this.validate(epoch);\n",
    "        }\n",
    "    }\n",
    "    predict(x,y,yToLabelFn=(a=>a)) {\n",
    "        const preds=this.forward(x);\n",
    "        return preds.map((pred,rowIndex) => {\n",
    "            const row=[pred,yToLabelFn(pred)];\n",
    "            if (y!=null) {\n",
    "                row.push(yToLabelFn(y[rowIndex]));\n",
    "            }\n",
    "            return row;\n",
    "        });\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-compilation",
   "metadata": {},
   "source": [
    "## Train a linear model to classify iris flowers\n",
    "\n",
    "Note: we use `BinaryCrossEntropyLoss` here just as an example. README.md and index.ipynb shows how to train with `CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "agreed-publication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -1 valid loss 1.5204031253227748 metrics [ 0.1 ]\n",
      "epoch 0 valid loss 1.3091236091890934 metrics [ 0.13333333333333333 ]\n",
      "epoch 1 valid loss 1.125123067421352 metrics [ 0.23333333333333334 ]\n",
      "epoch 2 valid loss 0.9699143897371635 metrics [ 0.23333333333333334 ]\n",
      "epoch 3 valid loss 0.8436669648668303 metrics [ 0.23333333333333334 ]\n",
      "epoch 4 valid loss 0.744136815804359 metrics [ 0.23333333333333334 ]\n",
      "epoch 5 valid loss 0.6666801248639437 metrics [ 0.4666666666666667 ]\n",
      "epoch 6 valid loss 0.6071409766744876 metrics [ 0.5666666666666667 ]\n",
      "epoch 7 valid loss 0.5605350246403263 metrics [ 0.6 ]\n",
      "epoch 8 valid loss 0.5236785153952593 metrics [ 0.6666666666666666 ]\n",
      "epoch 9 valid loss 0.4947260913944664 metrics [ 0.8333333333333334 ]\n",
      "epoch 10 valid loss 0.47106325376466057 metrics [ 0.8 ]\n",
      "epoch 11 valid loss 0.451684116797768 metrics [ 0.8 ]\n",
      "epoch 12 valid loss 0.4356360034389249 metrics [ 0.8 ]\n",
      "epoch 13 valid loss 0.42192982563261666 metrics [ 0.8 ]\n",
      "epoch 14 valid loss 0.4102082428217775 metrics [ 0.8333333333333334 ]\n",
      "epoch 15 valid loss 0.40006596997720206 metrics [ 0.9 ]\n",
      "epoch 16 valid loss 0.3912206368015754 metrics [ 0.9 ]\n",
      "epoch 17 valid loss 0.3835031251478794 metrics [ 0.9 ]\n",
      "epoch 18 valid loss 0.3765867062513287 metrics [ 0.9 ]\n",
      "epoch 19 valid loss 0.3704635314036926 metrics [ 0.8666666666666667 ]\n",
      "epoch 20 valid loss 0.3649644755017463 metrics [ 0.8666666666666667 ]\n",
      "epoch 21 valid loss 0.3599544335035585 metrics [ 0.8666666666666667 ]\n",
      "epoch 22 valid loss 0.355421798311273 metrics [ 0.8666666666666667 ]\n",
      "epoch 23 valid loss 0.351318450492688 metrics [ 0.8666666666666667 ]\n",
      "epoch 24 valid loss 0.34756142143213037 metrics [ 0.8666666666666667 ]\n"
     ]
    }
   ],
   "source": [
    "let stringData=require('fs').readFileSync('data/iris.data').toString();\n",
    "let data=parseCsv(stringData, new IrisRowHandler()).result;\n",
    "let lossFn=new BinaryCrossEntropyLoss();\n",
    "let model=[new Linear(4,3), new Sigmoid()];\n",
    "let learn=new Learner(model, lossFn, data);\n",
    "learn.fit(25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-cleaner",
   "metadata": {},
   "source": [
    "## Train a neural net to classify iris flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "disabled-limitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch -1 valid loss 0.9112650310020266 metrics [ 0.06666666666666667 ]\n",
      "epoch 0 valid loss 0.4691261728229647 metrics [ 0.8 ]\n",
      "epoch 1 valid loss 0.3580242946436428 metrics [ 0.8333333333333334 ]\n",
      "epoch 2 valid loss 0.31304584006049124 metrics [ 0.8333333333333334 ]\n",
      "epoch 3 valid loss 0.28940128310183194 metrics [ 0.8333333333333334 ]\n",
      "epoch 4 valid loss 0.2722530307901382 metrics [ 0.8666666666666667 ]\n",
      "epoch 5 valid loss 0.25807572576302173 metrics [ 0.8666666666666667 ]\n",
      "epoch 6 valid loss 0.2485991630696928 metrics [ 0.8333333333333334 ]\n",
      "epoch 7 valid loss 0.2413695793641617 metrics [ 0.8333333333333334 ]\n",
      "epoch 8 valid loss 0.2354008805581669 metrics [ 0.8333333333333334 ]\n",
      "epoch 9 valid loss 0.23168153001376693 metrics [ 0.8333333333333334 ]\n",
      "epoch 10 valid loss 0.22632484777798076 metrics [ 0.8333333333333334 ]\n",
      "epoch 11 valid loss 0.22261109293322623 metrics [ 0.8333333333333334 ]\n",
      "epoch 12 valid loss 0.22026958594314855 metrics [ 0.8666666666666667 ]\n",
      "epoch 13 valid loss 0.21610358401448726 metrics [ 0.8666666666666667 ]\n",
      "epoch 14 valid loss 0.21265551064889002 metrics [ 0.8666666666666667 ]\n",
      "epoch 15 valid loss 0.209856660640373 metrics [ 0.8666666666666667 ]\n",
      "epoch 16 valid loss 0.20805464613888885 metrics [ 0.8666666666666667 ]\n",
      "epoch 17 valid loss 0.2066004627015177 metrics [ 0.8666666666666667 ]\n",
      "epoch 18 valid loss 0.2047838707195562 metrics [ 0.8666666666666667 ]\n",
      "epoch 19 valid loss 0.20391894634462607 metrics [ 0.9 ]\n",
      "epoch 20 valid loss 0.2007573763556466 metrics [ 0.9 ]\n",
      "epoch 21 valid loss 0.19857633713982625 metrics [ 0.9 ]\n",
      "epoch 22 valid loss 0.1963538486224805 metrics [ 0.9 ]\n",
      "epoch 23 valid loss 0.19437692351540378 metrics [ 0.9 ]\n",
      "epoch 24 valid loss 0.19333992813223158 metrics [ 0.9 ]\n"
     ]
    }
   ],
   "source": [
    "let model=[new Linear(4,50), new ReLU(), new Linear(50,3), new Sigmoid()];\n",
    "let learn=new Learner(model, lossFn, data);\n",
    "learn.fit(25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-coordination",
   "metadata": {},
   "source": [
    "### Look at some predictions \n",
    "\n",
    "We use the lambda ```(y=>`${argmax(y)}: ${IRIS_CLASS_MAP[argmax(y)]}`)``` to convert predictions like `[0.000, 0.183, 0.843]` to readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sensitive-checkout",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [\n",
      "  [ 0.0011209508142939284, 0.868588948674408, 0.18839857907396682 ],\n",
      "  '1: Iris-versicolor',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "1 [\n",
      "  [ 0.03160294893152106, 0.8619210305769701, 0.0686605377396662 ],\n",
      "  '1: Iris-versicolor',\n",
      "  '1: Iris-versicolor'\n",
      "]\n",
      "2 [\n",
      "  [ 0.9563865002933649, 0.05844710206620156, 0.0022523456298663234 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "3 [\n",
      "  [ 0.9514775134519834, 0.07523967446272668, 0.0011493026435126436 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "4 [\n",
      "  [ 0.4078765566556188, 0.747607683074964, 0.00045367027710275777 ],\n",
      "  '1: Iris-versicolor',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "5 [\n",
      "  [ 0.010986773110423582, 0.11516426466816512, 0.9204752847569533 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "6 [\n",
      "  [ 0.9349790667787307, 0.0895305373210309, 0.004379558107638215 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n",
      "7 [\n",
      "  [ 0.000031527650954552385, 0.10930666946114984, 0.920677373630896 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "8 [\n",
      "  [ 0.0036005866175615286, 0.042814835829574065, 0.9433175377741122 ],\n",
      "  '2: Iris-virginica',\n",
      "  '2: Iris-virginica'\n",
      "]\n",
      "9 [\n",
      "  [ 0.9779041356237164, 0.035128180784859284, 0.0008067290869743284 ],\n",
      "  '0: Iris-setosa',\n",
      "  '0: Iris-setosa'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "// head(learn.predict(learn.xValid, learn.yValid)); run this to see \"raw\" targets\n",
    "head(learn.predict(learn.xValid, learn.yValid, (y=>`${argmax(y)}: ${IRIS_CLASS_MAP[argmax(y)]}`)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-liabilities",
   "metadata": {},
   "source": [
    "Show how we could train a linear layer without `Learner` - this is not a proper training loop, we just;\n",
    "- forward pass\n",
    "- print training loss\n",
    "- backward pass\n",
    "- update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "western-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape(x) [ 150, 4 ] shape(y) [ 150, 3 ]\n",
      "epoch 0 loss_value 1.0985206688321374\n",
      "epoch 1 loss_value 1.035577401241871\n",
      "epoch 2 loss_value 0.9764822829178839\n",
      "epoch 3 loss_value 0.9213514939129728\n",
      "epoch 4 loss_value 0.8702623923928795\n",
      "epoch 5 loss_value 0.823239612585144\n",
      "epoch 6 loss_value 0.7802451401146258\n",
      "epoch 7 loss_value 0.7411744189432343\n",
      "epoch 8 loss_value 0.7058593963417175\n",
      "epoch 9 loss_value 0.6740779355375611\n"
     ]
    }
   ],
   "source": [
    "let data=parseCsv(stringData, new IrisRowHandler()).result;\n",
    "let x=data[0],y=data[1];\n",
    "console.log('shape(x)',shape(x), 'shape(y)',shape(y));\n",
    "let loss_fn=new BinaryCrossEntropyLoss()\n",
    "let sig=new Sigmoid()\n",
    "let lin=new Linear(4,3);\n",
    "for (let epoch = 0; epoch < 10; epoch++) {\n",
    "    let y_pred=sig.forward(lin.forward(x));\n",
    "    let loss_value=loss_fn.forward(y_pred,y);\n",
    "    console.log('epoch',epoch,'loss_value',loss_value);\n",
    "    loss_fn.backward();\n",
    "    sig.backward(loss_fn.grad);\n",
    "    lin.backward(sig.grad);\n",
    "    lin.update(.1);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-november",
   "metadata": {},
   "source": [
    "## Can we teach a linear layer to convert one hot encoded integers to their bitwise representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "regulated-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "let x=[\n",
    "    [1,0,0,0,0,0,0,0,0,0],\n",
    "    [0,1,0,0,0,0,0,0,0,0],\n",
    "    [0,0,1,0,0,0,0,0,0,0],\n",
    "    [0,0,0,1,0,0,0,0,0,0],\n",
    "    [0,0,0,0,1,0,0,0,0,0],\n",
    "    [0,0,0,0,0,1,0,0,0,0],\n",
    "    [0,0,0,0,0,0,1,0,0,0],\n",
    "    [0,0,0,0,0,0,0,1,0,0],\n",
    "    [0,0,0,0,0,0,0,0,1,0],\n",
    "    [0,0,0,0,0,0,0,0,0,1]\n",
    "];\n",
    "let y=[\n",
    "    [0,0,0,0],\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [1,1,0,0],\n",
    "    [0,0,1,0],\n",
    "    [1,0,1,0],\n",
    "    [0,1,1,0],\n",
    "    [1,1,1,0],\n",
    "    [0,0,0,1],\n",
    "    [1,0,0,1]\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-fight",
   "metadata": {},
   "source": [
    "`x` is an identity matrix, so ... `x.y` is `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sixth-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEq(y,dotProduct(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-count",
   "metadata": {},
   "source": [
    "so ... will `y` make the perfect weights (if bias is zero)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adult-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss_value 0.01817239238895991\n",
      "[\n",
      "  [\n",
      "    0.018346571965820773,\n",
      "    0.01789284935833282,\n",
      "    0.017857961859873598,\n",
      "    0.018106322765750707\n",
      "  ],\n",
      "  [\n",
      "    0.9823319504531975,\n",
      "    0.017878673813708754,\n",
      "    0.018510728075674984,\n",
      "    0.018253139927648116\n",
      "  ],\n",
      "  [\n",
      "    0.01831435416274833,\n",
      "    0.9823831160511766,\n",
      "    0.0177013929780844,\n",
      "    0.017759857283000436\n",
      "  ],\n",
      "  [\n",
      "    0.9824892778131794,\n",
      "    0.9818210178477551,\n",
      "    0.018181094307748235,\n",
      "    0.01760498668248131\n",
      "  ],\n",
      "  [\n",
      "    0.01803044907905115,\n",
      "    0.018357491465425733,\n",
      "    0.9815807065162295,\n",
      "    0.018349313933759687\n",
      "  ],\n",
      "  [\n",
      "    0.9815440512194518,\n",
      "    0.01835549957560014,\n",
      "    0.9824442569091367,\n",
      "    0.017934759688817126\n",
      "  ],\n",
      "  [\n",
      "    0.017428776777345053,\n",
      "    0.9824373227261594,\n",
      "    0.9815920319748943,\n",
      "    0.018043250190070633\n",
      "  ],\n",
      "  [\n",
      "    0.9821080543156853,\n",
      "    0.9819669682198938,\n",
      "    0.981974034046849,\n",
      "    0.018109569625291297\n",
      "  ],\n",
      "  [\n",
      "    0.017907372398934297,\n",
      "    0.01828016343947588,\n",
      "    0.01779438811271174,\n",
      "    0.9819824314820048\n",
      "  ],\n",
      "  [\n",
      "    0.9816724153209007,\n",
      "    0.01836804331741892,\n",
      "    0.01774285160962259,\n",
      "    0.9824533470682494\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "let loss_fn=new BinaryCrossEntropyLoss()\n",
    "let sig=new Sigmoid()\n",
    "let linearNoBias=new Linear(10,4,false);\n",
    "let y_pred=null;\n",
    "for (let epoch = 0; epoch<10; epoch++) {\n",
    "    y_pred=sig.forward(linearNoBias.forward(x));\n",
    "    const loss_value=loss_fn.forward(y_pred,y);\n",
    "    if (epoch%10==9) {\n",
    "        console.log('epoch',epoch,'loss_value',loss_value);\n",
    "    }\n",
    "    loss_fn.backward();\n",
    "    sig.backward(loss_fn.grad);\n",
    "    linearNoBias.backward(sig.grad);\n",
    "    linearNoBias.update(50);\n",
    "}\n",
    "console.log(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-skirt",
   "metadata": {},
   "source": [
    "dump our linear layer to output - so we can look at the learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "statewide-cholesterol",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear {\n",
      "  inputDim: 10,\n",
      "  numHidden: 4,\n",
      "  weights: [\n",
      "    [\n",
      "      -4.071528438085275,\n",
      "      -4.094763508053605,\n",
      "      -4.0965762975366085,\n",
      "      -4.083753443318915\n",
      "    ],\n",
      "    [\n",
      "      4.106511635997528,\n",
      "      -4.095499624377472,\n",
      "      -4.06327426375718,\n",
      "      -4.076262078735197\n",
      "    ],\n",
      "    [\n",
      "      -4.073157778804889,\n",
      "      4.109208033089979,\n",
      "      -4.104758971682219,\n",
      "      -4.101694407727017\n",
      "    ],\n",
      "    [\n",
      "      4.114829651753304,\n",
      "      4.0800378396629,\n",
      "      -4.079930069248298,\n",
      "      -4.1098362186275255\n",
      "    ],\n",
      "    [\n",
      "      -4.087650601831166,\n",
      "      -4.070976909705129,\n",
      "      4.0678620313224565,\n",
      "      -4.071389911908574\n",
      "    ],\n",
      "    [\n",
      "      4.066019892491755,\n",
      "      -4.071077490837238,\n",
      "      4.112441183593208,\n",
      "      -4.092590828865962\n",
      "    ],\n",
      "    [\n",
      "      -4.119194038917194,\n",
      "      4.112073893487588,\n",
      "      4.0684320003835115,\n",
      "      -4.086991851218199\n",
      "    ],\n",
      "    [\n",
      "      4.0948104158539165,\n",
      "      4.087517654384536,\n",
      "      4.0878814244941,\n",
      "      -4.08358706509153\n",
      "    ],\n",
      "    [\n",
      "      -4.094009997444608,\n",
      "      -4.074890279151792,\n",
      "      -4.099889474719747,\n",
      "      4.088313949569252\n",
      "    ],\n",
      "    [\n",
      "      4.072488302375424,\n",
      "      -4.07044428671814,\n",
      "      -4.1025846854404,\n",
      "      4.1129229077910985\n",
      "    ]\n",
      "  ],\n",
      "  bias: [ 0, 0, 0, 0 ],\n",
      "  updateBias: false,\n",
      "  x: [\n",
      "    [\n",
      "      1, 0, 0, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 1, 0, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 1, 0, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 1, 0,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 1,\n",
      "      0, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      1, 0, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 1, 0, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 1, 0, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 0, 1, 0\n",
      "    ],\n",
      "    [\n",
      "      0, 0, 0, 0, 0,\n",
      "      0, 0, 0, 0, 1\n",
      "    ]\n",
      "  ],\n",
      "  weightsGradient: [\n",
      "    [\n",
      "      0.018346571965820773,\n",
      "      0.017892849358332824,\n",
      "      0.017857961859873598,\n",
      "      0.018106322765750707\n",
      "    ],\n",
      "    [\n",
      "      -0.017668049546802456,\n",
      "      0.017878673813708754,\n",
      "      0.018510728075674984,\n",
      "      0.018253139927648116\n",
      "    ],\n",
      "    [\n",
      "      0.01831435416274833,\n",
      "      -0.017616883948823436,\n",
      "      0.0177013929780844,\n",
      "      0.017759857283000436\n",
      "    ],\n",
      "    [\n",
      "      -0.017510722186820593,\n",
      "      -0.018178982152244894,\n",
      "      0.018181094307748235,\n",
      "      0.01760498668248131\n",
      "    ],\n",
      "    [\n",
      "      0.018030449079051148,\n",
      "      0.018357491465425733,\n",
      "      -0.018419293483770475,\n",
      "      0.018349313933759687\n",
      "    ],\n",
      "    [\n",
      "      -0.018455948780548237,\n",
      "      0.01835549957560014,\n",
      "      -0.01755574309086327,\n",
      "      0.017934759688817126\n",
      "    ],\n",
      "    [\n",
      "      0.01742877677734505,\n",
      "      -0.017562677273840643,\n",
      "      -0.018407968025105692,\n",
      "      0.018043250190070633\n",
      "    ],\n",
      "    [\n",
      "      -0.017891945684314736,\n",
      "      -0.01803303178010618,\n",
      "      -0.01802596595315098,\n",
      "      0.0181095696252913\n",
      "    ],\n",
      "    [\n",
      "      0.0179073723989343,\n",
      "      0.01828016343947588,\n",
      "      0.017794388112711737,\n",
      "      -0.018017568517995186\n",
      "    ],\n",
      "    [\n",
      "      -0.01832758467909934,\n",
      "      0.01836804331741892,\n",
      "      0.01774285160962259,\n",
      "      -0.017546652931750617\n",
      "    ]\n",
      "  ],\n",
      "  biasGradient: [\n",
      "    0.00017327350631423863,\n",
      "    0.0377411458149471,\n",
      "    0.03537944639082513,\n",
      "    0.10859697864707352\n",
      "  ],\n",
      "  xGradient: [\n",
      "    [\n",
      "      -0.2885463548910516,\n",
      "      -0.14102359330272848,\n",
      "      -0.14547994461739253,\n",
      "      0.00120778084777301,\n",
      "      -0.14559706576244302,\n",
      "      0.001097655381475382,\n",
      "      -0.00332546080944722,\n",
      "      0.1441009192944158,\n",
      "      -0.14397797139262655,\n",
      "      0.003048232548880647\n",
      "    ],\n",
      "    [\n",
      "      -0.14836084087652454,\n",
      "      -0.28885674441977793,\n",
      "      -0.0053524686337359795,\n",
      "      -0.14708396117275452,\n",
      "      0.0004386972207708062,\n",
      "      -0.1399192165433628,\n",
      "      0.14383911257211318,\n",
      "      0.0018164161075617524,\n",
      "      -0.0017331021803138058,\n",
      "      -0.14229334035902896\n",
      "    ],\n",
      "    [\n",
      "      -0.14418009614472582,\n",
      "      0.003105069751065212,\n",
      "      -0.2861215440373726,\n",
      "      -0.13855739475889967,\n",
      "      -0.0034119910318743674,\n",
      "      0.14303024738219738,\n",
      "      -0.14533380886416508,\n",
      "      0.0027844814084884567,\n",
      "      -0.003153570104898973,\n",
      "      0.14343300569202394\n",
      "    ],\n",
      "    [\n",
      "      -0.0006561121731131214,\n",
      "      -0.1398820030707651,\n",
      "      -0.1470463096181769,\n",
      "      -0.28636783655023135,\n",
      "      0.14455889781867454,\n",
      "      0.005458030644309997,\n",
      "      -0.0006208701721642229,\n",
      "      -0.14041828629464276,\n",
      "      0.14000284782979966,\n",
      "      0.000506260610449949\n",
      "    ],\n",
      "    [\n",
      "      -0.1447462435799404,\n",
      "      -0.001076707865308127,\n",
      "      0.0023706106961450396,\n",
      "      0.14552178977739127,\n",
      "      -0.29137914474601256,\n",
      "      -0.1489838666723729,\n",
      "      -0.14540477150884298,\n",
      "      -0.001305654106781684,\n",
      "      0.0019136504583405767,\n",
      "      0.1465314556004996\n",
      "    ],\n",
      "    [\n",
      "      -0.0013349473579609,\n",
      "      -0.1494542482726675,\n",
      "      0.145831658969281,\n",
      "      -0.0032044168896079722,\n",
      "      -0.14043385120731422,\n",
      "      -0.2888284792944918,\n",
      "      0.006792894057416246,\n",
      "      -0.14234684382343504,\n",
      "      0.14290927415114657,\n",
      "      -0.003842349043444243\n",
      "    ],\n",
      "    [\n",
      "      0.0026961105667707846,\n",
      "      0.14158037506307725,\n",
      "      -0.13849050219104803,\n",
      "      0.0009937552862759463,\n",
      "      -0.1447777522254747,\n",
      "      -0.007166899922268863,\n",
      "      -0.2862626125099804,\n",
      "      -0.14603373792026247,\n",
      "      0.14614150714020058,\n",
      "      0.28577099420122354\n",
      "    ],\n",
      "    [\n",
      "      0.14335365623910906,\n",
      "      -0.00024115742989960776,\n",
      "      -0.0015497109834846923,\n",
      "      -0.14491939529514022,\n",
      "      -0.00045676956247013567,\n",
      "      -0.1443786329568107,\n",
      "      -0.14448659095295693,\n",
      "      -0.2881234573853978,\n",
      "      0.2881890248705041,\n",
      "      0.1457694786408799\n",
      "    ],\n",
      "    [\n",
      "      -0.1438442697414717,\n",
      "      -0.00013398424578529855,\n",
      "      0.0030429193152717443,\n",
      "      0.14652112505501935,\n",
      "      -0.0018751131936905474,\n",
      "      0.14215622825958366,\n",
      "      0.14413035975269284,\n",
      "      0.2878799644323413,\n",
      "      -0.2879385662457788,\n",
      "      -0.1453914608743433\n",
      "    ],\n",
      "    [\n",
      "      -0.0016624818605751046,\n",
      "      -0.14775626801081204,\n",
      "      0.14598614199502918,\n",
      "      -0.0007448372724079971,\n",
      "      0.1405454043560665,\n",
      "      -0.004274228911269773,\n",
      "      0.2884981023071384,\n",
      "      0.14101112649899028,\n",
      "      -0.14109718697531964,\n",
      "      -0.2878846573445997\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "linearNoBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "strategic-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "export {accuracy,Sigmoid,MSE,BinaryCrossEntropyLoss,CrossEntropyLoss,ReLU,Linear,Learner}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "jslab"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "text/javascript",
   "name": "javascript",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
