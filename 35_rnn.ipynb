{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinct-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "//default_exp rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-restaurant",
   "metadata": {},
   "source": [
    "# rnn\n",
    "\n",
    "> Implement some of the language models in https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-section",
   "metadata": {},
   "source": [
    "## Set-up data used in tests / demos\n",
    "    \n",
    "Using [human_numbers.tgz](https://s3.amazonaws.com/fast-ai-sample/human_numbers.tgz), I created an even smaller dataset with the following;\n",
    "\n",
    "```\n",
    "lines = []\n",
    "with open('data/human_numbers/train.txt') as f: lines.extend(f.readlines())\n",
    "with open('data/human_numbers/valid.txt') as f: lines.extend(f.readlines())\n",
    "with open('data/human_numbers/train_and_valid.txt','w') as f:\n",
    "    f.write(' . '.join([l.strip() for l in lines[:2000]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statistical-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo\n"
     ]
    }
   ],
   "source": [
    "const text=require('fs').readFileSync('data/human_numbers/train_and_valid.txt').toString();\n",
    "text.substring(0,100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broadband-grove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  'one',      '.',        'two',\n",
      "  'three',    'four',     'five',\n",
      "  'six',      'seven',    'eight',\n",
      "  'nine',     'ten',      'eleven',\n",
      "  'twelve',   'thirteen', 'fourteen',\n",
      "  'fifteen',  'sixteen',  'seventeen',\n",
      "  'eighteen', 'nineteen', 'twenty',\n",
      "  'thirty',   'forty',    'fifty',\n",
      "  'sixty',    'seventy',  'eighty',\n",
      "  'ninety',   'hundred',  'thousand'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const tokens=text.split(' ');\n",
    "const vocab = [...new Set(tokens)];\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "present-playback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  one: 0,\n",
      "  '.': 1,\n",
      "  two: 2,\n",
      "  three: 3,\n",
      "  four: 4,\n",
      "  five: 5,\n",
      "  six: 6,\n",
      "  seven: 7,\n",
      "  eight: 8,\n",
      "  nine: 9,\n",
      "  ten: 10,\n",
      "  eleven: 11,\n",
      "  twelve: 12,\n",
      "  thirteen: 13,\n",
      "  fourteen: 14,\n",
      "  fifteen: 15,\n",
      "  sixteen: 16,\n",
      "  seventeen: 17,\n",
      "  eighteen: 18,\n",
      "  nineteen: 19,\n",
      "  twenty: 20,\n",
      "  thirty: 21,\n",
      "  forty: 22,\n",
      "  fifty: 23,\n",
      "  sixty: 24,\n",
      "  seventy: 25,\n",
      "  eighty: 26,\n",
      "  ninety: 27,\n",
      "  hundred: 28,\n",
      "  thousand: 29\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const word2idx={};\n",
    "vocab.forEach((word,idx)=>word2idx[word]=idx);\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dense-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   0,  1,  2,  1,  3, 1,  4,  1,  5,  1,  6, 1,\n",
      "   7,  1,  8,  1,  9, 1, 10,  1, 11,  1, 12, 1,\n",
      "  13,  1, 14,  1, 15, 1, 16,  1, 17,  1, 18, 1,\n",
      "  19,  1, 20,  1, 20, 0,  1, 20,  2,  1, 20, 3,\n",
      "   1, 20,  4,  1, 20, 5,  1, 20,  6,  1, 20, 7,\n",
      "   1, 20,  8,  1, 20, 9,  1, 21,  1, 21,  0, 1,\n",
      "  21,  2,  1, 21,  3, 1, 21,  4,  1, 21,  5, 1,\n",
      "  21,  6,  1, 21,  7, 1, 21,  8,  1, 21,  9, 1,\n",
      "  22,  1, 22,  0,\n",
      "  ... 10921 more items\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const nums=tokens.map(e=>word2idx[e]);\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "similar-muscle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mostCommonToken [ '.', 1999 ] 0.18138099990926412\n"
     ]
    }
   ],
   "source": [
    "const tokenCounter={};\n",
    "vocab.forEach(token=>tokenCounter[token]=0);\n",
    "tokens.forEach(token=>tokenCounter[token]++);\n",
    "let mostCommonToken=[null,0];\n",
    "for (let key in tokenCounter) {\n",
    "    if (tokenCounter[key]>mostCommonToken[1]) {\n",
    "        mostCommonToken=[key,tokenCounter[key]];\n",
    "    }\n",
    "}\n",
    "console.log('mostCommonToken', mostCommonToken, mostCommonToken[1]/tokens.length);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-easter",
   "metadata": {},
   "source": [
    "&uarr; if we can get better than 0.18 accuracy, our model will be doing better than predicting the most common token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "guided-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Imports we need in rnn.module.js\n",
    "*/\n",
    "import {round,flatten,exp,shape,transpose,dotProduct,randn,uniform,full,zeros} from './src/util.module.js';\n",
    "import {mean,reshape,argmax,normalize,identity,meanAndStandardDeviation} from './src/util.module.js';\n",
    "import {matrixSum1d,matrixSum2d,matrixSubtract1d,matrixSubtract2d,matrixMultiply1d,matrixMultiply2d} from './src/util.module.js';\n",
    "import {head,tail,shuffle,split,batches} from './src/data.module.js';\n",
    "import {accuracy} from './src/nn.module.js';\n",
    "import {CrossEntropyLoss} from './src/nn.module.js';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "available-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Imports we need for testing\n",
    "import {testEq} from './src/testutil.module.js'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-sentence",
   "metadata": {},
   "source": [
    "## Convert a sequence of tokens into a data structure that our language models can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contained-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Convert a 1d array of numbers (sequence of word indices) to a 2d array of shape [sequenceLength+1, nums.length/sequenceLength].\n",
    "This makes it easy to iterate over the 1st dimension of \"data\" to access a chunk of \"nums\", one timestep at a time.\n",
    "*/\n",
    "function toData(nums,sequenceLength) {\n",
    "    const data=full(sequenceLength+1).map(e=>[]);\n",
    "    const iMax=nums.length-sequenceLength;\n",
    "    for (let i=0; i<iMax; i+=sequenceLength) {\n",
    "        for (let j=0; j<sequenceLength+1; j++) {\n",
    "            data[j].push(nums[i+j]);\n",
    "        }\n",
    "    }\n",
    "    return data;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "altered-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEq([3,Math.floor(nums.length/2)],shape(toData(nums,2)));\n",
    "testEq([4,Math.floor(nums.length/3)],shape(toData(nums,3)));\n",
    "testEq([5,Math.floor(nums.length/4)],shape(toData(nums,4)));\n",
    "testEq([17,Math.floor(nums.length/16)],shape(toData(nums,16)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-statistics",
   "metadata": {},
   "source": [
    "## Implement \"multi-call\" ReLU, Linear and Embedding layers\n",
    "\n",
    "In the `nn` module, we implement these layers but they can only be used by models that call `forward` and `backward` once for each call to `update`.\n",
    "\n",
    "Our language models will make multiple calls to `forward`, followed by the same number of calls to `backward` for each call to `update`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "described-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class ReLU {\n",
    "    constructor() {\n",
    "        this.gradMasks=[];\n",
    "    }\n",
    "    forward(x2d) {\n",
    "        const gradMask=zeros(...shape(x2d));\n",
    "        this.gradMasks.push(gradMask);\n",
    "        return x2d.map((x1d,rowIndex) => x1d.map((x,colIndex) => {\n",
    "            if (x>0) {\n",
    "                gradMask[rowIndex][colIndex]=1;\n",
    "            }\n",
    "            return Math.max(0,x);\n",
    "        }));\n",
    "    }\n",
    "    backward(gradient) {\n",
    "        if (this.gradMasks.length <= 0) {\n",
    "            throw `ReLU: backward has been called too many times`;\n",
    "        }\n",
    "        return matrixMultiply2d(this.gradMasks.pop(),gradient);\n",
    "    }\n",
    "    update(lr) {\n",
    "        if (this.gradMasks.length != 0) {\n",
    "            throw new Error(`ReLU: forward has been called ${this.gradMasks.length} times more than backward`);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expanded-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "function _matrixSum2d(a,b) {\n",
    "    return (b == null) ? a : matrixSum2d(a,b);\n",
    "}\n",
    "function _matrixSum1d(a,b) {\n",
    "    return (b == null) ? a : matrixSum1d(a,b);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-worship",
   "metadata": {},
   "source": [
    "Note: For both `Linear` and `Embedding`, `backward` doesn't scale gradients relative to batch size, and `update` doesn't adjust `lr` to account for batch size either. So ... if we change batch size, we'll probably need to adjust learning rates too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "korean-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Applies a linear transformation to `x`.\n",
    "*/\n",
    "class Linear {\n",
    "    constructor(inputDim,numHidden=1,bias=true) {\n",
    "        this.inputDim=inputDim;\n",
    "        this.numHidden=numHidden;\n",
    "        this.weights=matrixMultiply2d(randn(inputDim,numHidden), Math.sqrt(2.0/inputDim));\n",
    "        this.bias=zeros(numHidden)\n",
    "        this.updateBias=bias;\n",
    "        this.xHistory=[];\n",
    "        this.weightsGradient=null;\n",
    "        this.biasGradient=null;\n",
    "        this.label=`${this.constructor.name}(${this.inputDim},${this.numHidden})`;\n",
    "    }\n",
    "    forward(x) {\n",
    "        this.xHistory.push(x);\n",
    "        return matrixSum2d(dotProduct(x,this.weights), this.bias);\n",
    "    }\n",
    "    backward(gradient) {\n",
    "        if (this.xHistory.length <= 0) {\n",
    "            throw `${this.label}: backward has been called too many times`;\n",
    "        }\n",
    "        let weightsGradient=dotProduct(transpose(this.xHistory.pop()), gradient);\n",
    "        this.weightsGradient=_matrixSum2d(weightsGradient,this.weightsGradient);\n",
    "        let biasGradient=transpose(gradient).map(col => col.reduce((a,b) => a+b));\n",
    "        this.biasGradient=_matrixSum1d(biasGradient,this.biasGradient);\n",
    "        return dotProduct(gradient,transpose(this.weights)); // xGradient\n",
    "    }\n",
    "    update(lr) {\n",
    "        if (this.xHistory.length != 0) {\n",
    "            throw new Error(`${this.label}: forward has been called ${this.xHistory.length} times more than backward`);\n",
    "        }\n",
    "        this.weights=matrixSubtract2d(this.weights,matrixMultiply2d(this.weightsGradient,lr));\n",
    "        if (this.updateBias) {\n",
    "            this.bias=matrixSubtract1d(this.bias,matrixMultiply1d(this.biasGradient,lr));\n",
    "        }\n",
    "        this.weightsGradient=null;\n",
    "        this.biasGradient=null;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "destroyed-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Using\n",
    "- `Embedding` when `x` is an array of IDs or\n",
    "- `Linear` when `x` is a one-hot encoded matrix\n",
    "should give the same results - but `Embedding` should be faster.\n",
    "*/\n",
    "class Embedding extends Linear {\n",
    "    constructor(inputDim,numHidden=1,bias=true) {\n",
    "        super(inputDim,numHidden,bias);\n",
    "        this.weights=uniform(inputDim,numHidden,-1,1);\n",
    "    }\n",
    "    forward(x) {\n",
    "        this.xHistory.push(x);\n",
    "        return matrixSum2d(x.map(i=>this.weights[i]), this.bias);\n",
    "    }\n",
    "    backward(gradient) {\n",
    "        if (this.xHistory.length <= 0) {\n",
    "            throw `${this.label}: backward has been called too many times`;\n",
    "        }\n",
    "        let weightsGradient=zeros(this.inputDim,this.numHidden);\n",
    "        let x=this.xHistory.pop();\n",
    "        for (let i=0; i<this.inputDim; i++) {\n",
    "            x.map((row, rowIndex)=>{\n",
    "                if (row == i) {\n",
    "                    weightsGradient[i]=matrixSum1d(weightsGradient[i],gradient[rowIndex]);\n",
    "                }\n",
    "            })\n",
    "        }\n",
    "        this.weightsGradient=_matrixSum2d(weightsGradient,this.weightsGradient);\n",
    "        let biasGradient=transpose(gradient).map(col => col.reduce((a,b) => a+b));\n",
    "        this.biasGradient=_matrixSum1d(biasGradient,this.biasGradient);\n",
    "        return dotProduct(gradient,transpose(this.weights));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-acoustic",
   "metadata": {},
   "source": [
    "## First recurrent model - predict next word from previous 3 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pressing-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel2 {\n",
    "    constructor(vocab_sz, n_hidden, sequenceLength) {\n",
    "        this.sequenceLength = sequenceLength || 3;\n",
    "        this.i_h = new Linear(vocab_sz, n_hidden);\n",
    "        this.h_h = new Linear(n_hidden, n_hidden);\n",
    "        this.h_o = new Linear(n_hidden, vocab_sz);\n",
    "        this.non_linear = new ReLU();\n",
    "        this.oneHotLookup = normalize(identity(vocab_sz));\n",
    "    }\n",
    "    \n",
    "    toOneHot(x) {\n",
    "        return x.map(e=>this.oneHotLookup[e]);\n",
    "    }\n",
    "    \n",
    "    forward(x) {\n",
    "        let h=0;\n",
    "        for (let i=0; i<this.sequenceLength; i++) {\n",
    "            h = matrixSum2d(this.i_h.forward(this.toOneHot(x[i])), h);\n",
    "            h = this.non_linear.forward(this.h_h.forward(h));\n",
    "        }\n",
    "        return this.h_o.forward(h);\n",
    "    }\n",
    "    \n",
    "    backward(gradients) {\n",
    "        let g=this.h_o.backward(gradients);\n",
    "        for (let i=this.sequenceLength; i>0; i--) {\n",
    "            g=this.non_linear.backward(g);\n",
    "            g=this.h_h.backward(g);\n",
    "            this.i_h.backward(g);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    update(lr) {\n",
    "        [this.i_h,this.h_h,this.h_o,this.non_linear].forEach(layer=>layer.update(lr));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-sucking",
   "metadata": {},
   "source": [
    "`constructor`\n",
    "- normalizing the one-hot lookup seems to make training more stable and slightly more accurate\n",
    "\n",
    "`forward`\n",
    "- If `i_h` was an embedding we wouldn't need `toOneHot`\n",
    "- When we `matrixSum2d(i_h.forward(), h)` we put `h` on the right so that the initial value `0` is re-shaped to match the shape of the output of `i_h` (which is `[n_hidden,n_hidden]`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surface-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "// train a model that predicts the next word after any number of input words\n",
    "function train(model_fn,data,dropLastBatch=false,shuffleBatch=true) {\n",
    "    console.log('Training model',model_fn);\n",
    "    let lossFn=new CrossEntropyLoss();\n",
    "    let model=new model_fn(vocab.length,28,data.length-1); // data.length-1 is sequence length\n",
    "    let lossValues=[];\n",
    "    let accuracyValues=[];\n",
    "    for (let epoch=0; epoch<10; epoch++) {\n",
    "        batches(data,64,dropLastBatch,shuffleBatch).forEach(batch => {\n",
    "            const xb=batch; // the model will look at only sequence length tokens\n",
    "            const yb=batch[model.sequenceLength];\n",
    "            let preds=model.forward(xb);\n",
    "            let lossValue=lossFn.forward(preds,yb);\n",
    "            lossValues.push(lossValue);\n",
    "            accuracyValues.push(accuracy(preds,yb));\n",
    "            model.backward(lossFn.backward());\n",
    "            model.update(3e-3);\n",
    "        });\n",
    "        console.log('epoch',epoch,new Date(),'train loss',round(mean(lossValues),3),\n",
    "                    'accuracy',round(mean(accuracyValues),3));\n",
    "        lossValues=[];\n",
    "        accuracyValues=[];\n",
    "        if (model.reset) {\n",
    "            model.reset();\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-documentation",
   "metadata": {},
   "source": [
    "Train a model to predict the next word after 3 input words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wireless-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [class LMModel2]\n",
      "epoch 0 2021-05-18T10:28:09.423Z train loss 2.011 accuracy 0.493\n",
      "epoch 1 2021-05-18T10:28:10.368Z train loss 1.45 accuracy 0.562\n",
      "epoch 2 2021-05-18T10:28:11.291Z train loss 1.391 accuracy 0.561\n",
      "epoch 3 2021-05-18T10:28:12.258Z train loss 1.358 accuracy 0.562\n",
      "epoch 4 2021-05-18T10:28:13.250Z train loss 1.344 accuracy 0.569\n",
      "epoch 5 2021-05-18T10:28:14.345Z train loss 1.351 accuracy 0.561\n",
      "epoch 6 2021-05-18T10:28:15.401Z train loss 1.338 accuracy 0.565\n",
      "epoch 7 2021-05-18T10:28:16.460Z train loss 1.326 accuracy 0.558\n",
      "epoch 8 2021-05-18T10:28:17.608Z train loss 1.322 accuracy 0.559\n",
      "epoch 9 2021-05-18T10:28:18.777Z train loss 1.313 accuracy 0.561\n"
     ]
    }
   ],
   "source": [
    "train(LMModel2,toData(nums,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-output",
   "metadata": {},
   "source": [
    "Train a model to predict the next word after 4 input words &darr; to show this model and training approach are not just doing well because of the sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "gross-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [class LMModel2]\n",
      "epoch 0 2021-05-18T10:28:19.862Z train loss 2.034 accuracy 0.486\n",
      "epoch 1 2021-05-18T10:28:20.929Z train loss 1.52 accuracy 0.537\n",
      "epoch 2 2021-05-18T10:28:22.054Z train loss 1.415 accuracy 0.554\n",
      "epoch 3 2021-05-18T10:28:23.086Z train loss 1.394 accuracy 0.545\n",
      "epoch 4 2021-05-18T10:28:24.148Z train loss 1.375 accuracy 0.555\n",
      "epoch 5 2021-05-18T10:28:25.210Z train loss 1.36 accuracy 0.556\n",
      "epoch 6 2021-05-18T10:28:26.224Z train loss 1.381 accuracy 0.558\n",
      "epoch 7 2021-05-18T10:28:27.252Z train loss 1.382 accuracy 0.549\n",
      "epoch 8 2021-05-18T10:28:28.268Z train loss 1.323 accuracy 0.557\n",
      "epoch 9 2021-05-18T10:28:29.297Z train loss 1.309 accuracy 0.567\n"
     ]
    }
   ],
   "source": [
    "train(LMModel2,toData(nums,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-astrology",
   "metadata": {},
   "source": [
    "## LMModel2 with an `Embedding`\n",
    "\n",
    "Using an embedding for the input to hidden layer makes training faster but ... if we one-hot encoded x, rather than call `toOneHot` in `LMModel2#forward`, we might see less of a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "known-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel2_2 extends LMModel2 {\n",
    "    constructor(vocab_sz, n_hidden, sequenceLength) {\n",
    "        super(vocab_sz, n_hidden, sequenceLength);\n",
    "        this.i_h=new Embedding(vocab_sz, n_hidden);\n",
    "        this.i_h.weights=uniform(vocab_sz, n_hidden,-2,2);\n",
    "    }\n",
    "    \n",
    "    forward(x) {\n",
    "        let h=0;\n",
    "        for (let i=0; i<3; i++) {\n",
    "            /* Use this chunk (and comment the line below) to see stats of i_h output\n",
    "            const _h=this.i_h.forward(x[i]);\n",
    "            console.log(meanAndStandardDeviation(flatten(_h)));\n",
    "            h = matrixSum2d(_h, h);\n",
    "            */\n",
    "            h = matrixSum2d(this.i_h.forward(x[i]), h);\n",
    "            h = this.non_linear.forward(this.h_h.forward(h));\n",
    "        }\n",
    "        return this.h_o.forward(h);\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "secondary-bowling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [class LMModel2_2 extends LMModel2]\n",
      "epoch 0 2021-05-18T10:28:30.173Z train loss 1.927 accuracy 0.493\n",
      "epoch 1 2021-05-18T10:28:30.979Z train loss 1.49 accuracy 0.553\n",
      "epoch 2 2021-05-18T10:28:31.931Z train loss 1.423 accuracy 0.552\n",
      "epoch 3 2021-05-18T10:28:32.738Z train loss 1.391 accuracy 0.554\n",
      "epoch 4 2021-05-18T10:28:33.607Z train loss 1.366 accuracy 0.557\n",
      "epoch 5 2021-05-18T10:28:34.413Z train loss 1.355 accuracy 0.566\n",
      "epoch 6 2021-05-18T10:28:35.137Z train loss 1.344 accuracy 0.564\n",
      "epoch 7 2021-05-18T10:28:35.895Z train loss 1.333 accuracy 0.558\n",
      "epoch 8 2021-05-18T10:28:36.693Z train loss 1.32 accuracy 0.565\n",
      "epoch 9 2021-05-18T10:28:37.493Z train loss 1.315 accuracy 0.562\n"
     ]
    }
   ],
   "source": [
    "train(LMModel2_2,toData(nums,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-camping",
   "metadata": {},
   "source": [
    "# Maintaining the State of an RNN\n",
    "\n",
    "Organise data so the model sees contiguous text over subsequent batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "printable-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "function groupChunks(ds,bs=64) {\n",
    "    const m = Math.floor(ds[0].length/bs);\n",
    "    const newDs = [...Array(ds.length).keys()].map(i=>[]);\n",
    "    for (let i=0; i<m; i++) {\n",
    "        for (let j=0; j<bs; j++) {\n",
    "            for (let k=0; k<ds.length; k++) {\n",
    "                newDs[k].push(ds[k][i + m*j]);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return newDs;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "together-floor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4, 3648 ]\n",
      "0 0 x one . two y .\n",
      "0 1 x sixty six . y sixty\n",
      "0 2 x hundred eighteen . y one\n",
      "0 3 x three . one y hundred\n",
      "0 4 x eighty eight . y one\n",
      "1 0 x . three . y four\n",
      "1 1 x sixty seven . y sixty\n",
      "1 2 x one hundred nineteen y .\n",
      "1 3 x hundred fifty four y .\n",
      "1 4 x one hundred eighty y nine\n",
      "2 0 x four . five y .\n",
      "2 1 x sixty eight . y sixty\n",
      "2 2 x . one hundred y twenty\n",
      "2 3 x . one hundred y fifty\n",
      "2 4 x nine . one y hundred\n"
     ]
    }
   ],
   "source": [
    "let _dataTemp = toData(nums,3);\n",
    "let _data=groupChunks(_dataTemp);\n",
    "\n",
    "console.log(shape(_data));\n",
    "let _batches=batches(_data,64,true,false);\n",
    "for (let b=0; b<3; b++) {\n",
    "    let _batch=_batches[b];\n",
    "    [...Array(5).keys()].forEach(i => {\n",
    "        console.log(b,i,'x',vocab[_batch[0][i]],vocab[_batch[1][i]],vocab[_batch[2][i]],'y',vocab[_batch[3][i]]);\n",
    "    });\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-cameroon",
   "metadata": {},
   "source": [
    "here's how we could move the initialization of `h` out of `forward` &darr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "turned-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel3 extends LMModel2 {\n",
    "    constructor(vocab_sz, n_hidden, sequenceLength) {\n",
    "        super(vocab_sz, n_hidden, sequenceLength);\n",
    "        this.h=0;\n",
    "    }\n",
    "    \n",
    "    forward(x) {\n",
    "        for (let i=0; i<3; i++) {\n",
    "            this.h = matrixSum2d(this.i_h.forward(this.toOneHot(x[i])), this.h);\n",
    "            this.h = this.non_linear.forward(this.h_h.forward(this.h));\n",
    "        }\n",
    "        return this.h_o.forward(this.h);\n",
    "    }\n",
    "        \n",
    "    reset() {\n",
    "        this.h=0;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-thing",
   "metadata": {},
   "source": [
    "without organising the data so the model sees contiguous text over subsequent batches, we loose a little accuracy (~2%) but i thought we'd loose more. Maybe if we were looking at validation accuracy we'd see more of a difference.\n",
    "\n",
    "organising the data with `groupChunks` improves a little over our fist model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "concerned-friend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [class LMModel3 extends LMModel2]\n",
      "epoch 0 2021-05-18T10:28:38.814Z train loss 1.985 accuracy 0.477\n",
      "epoch 1 2021-05-18T10:28:39.896Z train loss 1.446 accuracy 0.559\n",
      "epoch 2 2021-05-18T10:28:40.952Z train loss 1.376 accuracy 0.56\n",
      "epoch 3 2021-05-18T10:28:42.019Z train loss 1.333 accuracy 0.567\n",
      "epoch 4 2021-05-18T10:28:43.014Z train loss 1.291 accuracy 0.57\n",
      "epoch 5 2021-05-18T10:28:44.038Z train loss 1.245 accuracy 0.576\n",
      "epoch 6 2021-05-18T10:28:45.090Z train loss 1.198 accuracy 0.585\n",
      "epoch 7 2021-05-18T10:28:46.122Z train loss 1.157 accuracy 0.589\n",
      "epoch 8 2021-05-18T10:28:47.123Z train loss 1.117 accuracy 0.597\n",
      "epoch 9 2021-05-18T10:28:48.163Z train loss 1.091 accuracy 0.6\n"
     ]
    }
   ],
   "source": [
    "// train(LMModel3,toData(nums,3));\n",
    "train(LMModel3,groupChunks(toData(nums,3)),true,false);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-india",
   "metadata": {},
   "source": [
    "we should expect similar results when `i_h` is an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "israeli-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel3_2 extends LMModel2_2 {\n",
    "    constructor(vocab_sz, n_hidden, sequenceLength) {\n",
    "        super(vocab_sz, n_hidden, sequenceLength);\n",
    "        this.h=0;\n",
    "    }\n",
    "    \n",
    "    forward(x) {\n",
    "        for (let i=0; i<3; i++) {\n",
    "            this.h = matrixSum2d(this.i_h.forward(x[i]), this.h);\n",
    "            this.h = this.non_linear.forward(this.h_h.forward(this.h));\n",
    "        }\n",
    "        return this.h_o.forward(this.h);\n",
    "    }\n",
    "        \n",
    "    reset() {\n",
    "        this.h=0;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "progressive-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model [class LMModel3_2 extends LMModel2_2]\n",
      "epoch 0 2021-05-18T10:28:49.045Z train loss 2.116 accuracy 0.452\n",
      "epoch 1 2021-05-18T10:28:49.805Z train loss 1.481 accuracy 0.546\n",
      "epoch 2 2021-05-18T10:28:50.563Z train loss 1.415 accuracy 0.558\n",
      "epoch 3 2021-05-18T10:28:51.324Z train loss 1.376 accuracy 0.566\n",
      "epoch 4 2021-05-18T10:28:52.084Z train loss 1.345 accuracy 0.568\n",
      "epoch 5 2021-05-18T10:28:52.854Z train loss 1.314 accuracy 0.572\n",
      "epoch 6 2021-05-18T10:28:53.608Z train loss 1.283 accuracy 0.575\n",
      "epoch 7 2021-05-18T10:28:54.397Z train loss 1.253 accuracy 0.577\n",
      "epoch 8 2021-05-18T10:28:55.172Z train loss 1.228 accuracy 0.582\n",
      "epoch 9 2021-05-18T10:28:55.933Z train loss 1.204 accuracy 0.585\n"
     ]
    }
   ],
   "source": [
    "train(LMModel3_2,groupChunks(toData(nums,3)),true,false);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-designation",
   "metadata": {},
   "source": [
    "# Flattening/un-flattening multi-dimensional arrays\n",
    "\n",
    "Up until now, our language models have returned a result of size `bs x vocab_sz`.\n",
    "\n",
    "Our next model will output a prediction per-timestep, so its result will be `sequence_length x bs x vocab_sz`. Note: Most deep learning code would make `bs` the 1st dimension, but it makes a this code more simple to deviate from this convention.\n",
    "\n",
    "We use `Flatten` below, to reshape data so that we can use `CrossEntropyLoss` and `accuracy` without modification.\n",
    "`Flatten` can also reverse the reshape, so we can take the signal returned by `CrossEntropyLoss` loss and feed it into the models `backward` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vital-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "*/\n",
    "class Flatten {\n",
    "    forward(x) {\n",
    "        this.originalShape=shape(x);\n",
    "        return [].concat(...x);\n",
    "    }\n",
    "    backward(x) {\n",
    "        const result=[];\n",
    "        for (let i=0; i<this.originalShape[0]; i++) {\n",
    "            const startFrom=i*this.originalShape[1];\n",
    "            result.push(x.slice(startFrom,startFrom+this.originalShape[1]));\n",
    "        }\n",
    "        return result;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-document",
   "metadata": {},
   "source": [
    "The following test shows that we can use the same flatten for multiple arrays, as long as the first 2 dimensions of the arrays are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "national-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "let a=[],b=[];\n",
    "for (let i=0; i<3; i++) {\n",
    "    a.push([]); b.push([]);\n",
    "    for (let j=0; j<2; j++) {\n",
    "        a[a.length-1].push(`${i}.${j}`);\n",
    "        let _b=[]; b[b.length-1].push(_b);\n",
    "        for (let k=0; k<4; k++) {\n",
    "            _b.push(`${i}.${j}.${k}`);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "let _a=JSON.stringify(a),_b=JSON.stringify(b); \n",
    "let flatten=new Flatten();\n",
    "let aFlat=flatten.forward(a);\n",
    "let bFlat=flatten.forward(b);\n",
    "testEq([6],shape(aFlat));\n",
    "testEq([6,4],shape(bFlat));\n",
    "let aUnflat=flatten.backward(aFlat);\n",
    "let bUnflat=flatten.backward(bFlat);\n",
    "testEq([3,2],shape(aUnflat));\n",
    "testEq([3,2,4],shape(bUnflat));\n",
    "testEq(_a,JSON.stringify(aUnflat));\n",
    "testEq(_b,JSON.stringify(bUnflat));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-turkey",
   "metadata": {},
   "source": [
    "# Creating More Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "covered-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel4 {\n",
    "    constructor(vocab_sz, n_hidden) {\n",
    "        this.i_h=new Embedding(vocab_sz, n_hidden);\n",
    "        this.i_h.weights=uniform(vocab_sz, n_hidden,-2,2);\n",
    "        this.h_h = new Linear(n_hidden, n_hidden);\n",
    "        this.h_o = new Linear(n_hidden, vocab_sz);\n",
    "        this.non_linear = new ReLU();\n",
    "        this.h=0;\n",
    "    }\n",
    "    \n",
    "    forward(x) {\n",
    "        return x.map(_x => {\n",
    "            this.h = matrixSum2d(this.i_h.forward(_x), this.h);\n",
    "            this.h = this.non_linear.forward(this.h_h.forward(this.h));\n",
    "            return this.h_o.forward(this.h);\n",
    "        });\n",
    "    }\n",
    "    \n",
    "    backward(gradients) {\n",
    "        let g=null;\n",
    "        for (let i=gradients.length-1; i>=0; i--) {\n",
    "            let _g=this.h_o.backward(gradients[i]);\n",
    "            g=_matrixSum2d(_g,g);\n",
    "            g=this.non_linear.backward(g);\n",
    "            g=this.h_h.backward(g);\n",
    "            this.i_h.backward(g);\n",
    "        }\n",
    "    }\n",
    "        \n",
    "    update(lr) {\n",
    "        [this.i_h,this.h_h,this.h_o,this.non_linear].forEach(layer=>layer.update(lr));\n",
    "    }\n",
    "    \n",
    "    reset() {\n",
    "        this.h=0;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sticky-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train2(model,data) {\n",
    "    let bs=64;\n",
    "    data=groupChunks(data,bs);\n",
    "    console.log('Training model',model.constructor.name,'n_hidden',model.i_h.numHidden,\n",
    "                'shape(data)',shape(data),'sequenceLength',data.length-1);\n",
    "    let lossFn=new CrossEntropyLoss();\n",
    "    let flatten=new Flatten();\n",
    "    let lossValues=[]; // it's ok to take the mean of lossValues/accuracyValues as all batches are the same size\n",
    "    let accuracyValues=[];\n",
    "    let lastAccuracyValues=[];\n",
    "    for (let epoch=0; epoch<15; epoch++) {\n",
    "        batches(data,bs,true,false).forEach(batch => {\n",
    "            const xb=batch.slice(0,batch.length-1);\n",
    "            const ybFlat=flatten.forward(batch.slice(1));\n",
    "            const preds=model.forward(xb);\n",
    "            const predsFlat=flatten.forward(preds);\n",
    "            const lossValue=lossFn.forward(predsFlat,ybFlat);\n",
    "            lossValues.push(lossValue);\n",
    "            accuracyValues.push(accuracy(predsFlat,ybFlat));\n",
    "            // track accuracy on just the last token - to compare with previous models\n",
    "            lastAccuracyValues.push(accuracy(preds[preds.length-1],batch[batch.length-1]));\n",
    "            model.backward(flatten.backward(lossFn.backward()));\n",
    "            model.update(3e-4);\n",
    "        });\n",
    "        console.log('epoch',epoch,new Date(),'train loss',round(mean(lossValues),3),\n",
    "                    'accuracy',round(mean(accuracyValues),3),\n",
    "                    'last token accuracy',round(mean(lastAccuracyValues),3));\n",
    "        lossValues=[];\n",
    "        accuracyValues=[];\n",
    "        lastAccuracyValues=[];\n",
    "        model.reset();\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "approximate-reading",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model LMModel4 n_hidden 28 shape(data) [ 4, 3648 ] sequenceLength 3\n",
      "epoch 0 2021-05-18T10:34:00.543Z train loss 2.784 accuracy 0.345 last token accuracy 0.346\n",
      "epoch 1 2021-05-18T10:34:06.482Z train loss 1.92 accuracy 0.49 last token accuracy 0.49\n",
      "epoch 2 2021-05-18T10:34:12.139Z train loss 1.709 accuracy 0.519 last token accuracy 0.526\n",
      "epoch 3 2021-05-18T10:34:17.721Z train loss 1.603 accuracy 0.532 last token accuracy 0.535\n",
      "epoch 4 2021-05-18T10:34:23.051Z train loss 1.546 accuracy 0.538 last token accuracy 0.54\n",
      "epoch 5 2021-05-18T10:34:28.379Z train loss 1.509 accuracy 0.541 last token accuracy 0.542\n",
      "epoch 6 2021-05-18T10:34:33.759Z train loss 1.483 accuracy 0.544 last token accuracy 0.546\n",
      "epoch 7 2021-05-18T10:34:39.090Z train loss 1.464 accuracy 0.547 last token accuracy 0.548\n",
      "epoch 8 2021-05-18T10:34:44.552Z train loss 1.45 accuracy 0.548 last token accuracy 0.551\n",
      "epoch 9 2021-05-18T10:34:49.926Z train loss 1.437 accuracy 0.549 last token accuracy 0.552\n",
      "epoch 10 2021-05-18T10:34:55.258Z train loss 1.427 accuracy 0.552 last token accuracy 0.557\n",
      "epoch 11 2021-05-18T10:35:00.619Z train loss 1.418 accuracy 0.554 last token accuracy 0.559\n",
      "epoch 12 2021-05-18T10:35:05.977Z train loss 1.41 accuracy 0.555 last token accuracy 0.561\n",
      "epoch 13 2021-05-18T10:35:11.390Z train loss 1.403 accuracy 0.556 last token accuracy 0.561\n",
      "epoch 14 2021-05-18T10:35:16.760Z train loss 1.397 accuracy 0.555 last token accuracy 0.563\n"
     ]
    }
   ],
   "source": [
    "train2(new LMModel4(vocab.length,28), toData(nums,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "removed-monkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model LMModel4 n_hidden 64 shape(data) [ 9, 1344 ] sequenceLength 8\n",
      "epoch 0 2021-05-18T10:37:25.061Z train loss 2.883 accuracy 0.402 last token accuracy 0.407\n",
      "epoch 1 2021-05-18T10:37:42.164Z train loss 1.659 accuracy 0.53 last token accuracy 0.537\n",
      "epoch 2 2021-05-18T10:37:59.376Z train loss 1.51 accuracy 0.544 last token accuracy 0.548\n",
      "epoch 3 2021-05-18T10:38:16.514Z train loss 1.46 accuracy 0.547 last token accuracy 0.554\n",
      "epoch 4 2021-05-18T10:38:33.738Z train loss 1.431 accuracy 0.55 last token accuracy 0.555\n",
      "epoch 5 2021-05-18T10:38:50.825Z train loss 1.408 accuracy 0.554 last token accuracy 0.561\n",
      "epoch 6 2021-05-18T10:39:08.044Z train loss 1.386 accuracy 0.556 last token accuracy 0.561\n",
      "epoch 7 2021-05-18T10:39:25.119Z train loss 1.359 accuracy 0.559 last token accuracy 0.565\n",
      "epoch 8 2021-05-18T10:39:42.283Z train loss 1.329 accuracy 0.565 last token accuracy 0.57\n",
      "epoch 9 2021-05-18T10:39:59.578Z train loss 1.298 accuracy 0.573 last token accuracy 0.577\n",
      "epoch 10 2021-05-18T10:40:17.003Z train loss 1.275 accuracy 0.576 last token accuracy 0.583\n",
      "epoch 11 2021-05-18T10:40:34.376Z train loss 1.253 accuracy 0.582 last token accuracy 0.583\n",
      "epoch 12 2021-05-18T10:40:51.619Z train loss 1.253 accuracy 0.585 last token accuracy 0.586\n",
      "epoch 13 2021-05-18T10:41:08.858Z train loss 1.231 accuracy 0.59 last token accuracy 0.589\n",
      "epoch 14 2021-05-18T10:41:26.061Z train loss 1.214 accuracy 0.595 last token accuracy 0.594\n"
     ]
    }
   ],
   "source": [
    "train2(new LMModel4(vocab.length,64), toData(nums,8));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "jslab"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "text/javascript",
   "name": "javascript",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
