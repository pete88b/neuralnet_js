{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinct-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "//default_exp rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-restaurant",
   "metadata": {},
   "source": [
    "# rnn\n",
    "\n",
    "> Implement some of the language models in https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-section",
   "metadata": {},
   "source": [
    "## Set-up data used in tests / demos\n",
    "    \n",
    "Using [human_numbers.tgz](https://s3.amazonaws.com/fast-ai-sample/human_numbers.tgz), I created an even smaller dataset with the following;\n",
    "\n",
    "```\n",
    "lines = []\n",
    "with open('data/human_numbers/train.txt') as f: lines.extend(f.readlines())\n",
    "with open('data/human_numbers/valid.txt') as f: lines.extend(f.readlines())\n",
    "with open('data/human_numbers/train_and_valid.txt','w') as f:\n",
    "    f.write(' . '.join([l.strip() for l in lines[:2000]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statistical-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo\n"
     ]
    }
   ],
   "source": [
    "const text=require('fs').readFileSync('data/human_numbers/train_and_valid.txt').toString()\n",
    "text.substring(0,100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broadband-grove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  'one',      '.',        'two',\n",
      "  'three',    'four',     'five',\n",
      "  'six',      'seven',    'eight',\n",
      "  'nine',     'ten',      'eleven',\n",
      "  'twelve',   'thirteen', 'fourteen',\n",
      "  'fifteen',  'sixteen',  'seventeen',\n",
      "  'eighteen', 'nineteen', 'twenty',\n",
      "  'thirty',   'forty',    'fifty',\n",
      "  'sixty',    'seventy',  'eighty',\n",
      "  'ninety',   'hundred',  'thousand'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const tokens=text.split(' ')\n",
    "const vocab = tokens.filter((item, i, ar) => ar.indexOf(item) === i);\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "present-playback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  one: 0,\n",
      "  '.': 1,\n",
      "  two: 2,\n",
      "  three: 3,\n",
      "  four: 4,\n",
      "  five: 5,\n",
      "  six: 6,\n",
      "  seven: 7,\n",
      "  eight: 8,\n",
      "  nine: 9,\n",
      "  ten: 10,\n",
      "  eleven: 11,\n",
      "  twelve: 12,\n",
      "  thirteen: 13,\n",
      "  fourteen: 14,\n",
      "  fifteen: 15,\n",
      "  sixteen: 16,\n",
      "  seventeen: 17,\n",
      "  eighteen: 18,\n",
      "  nineteen: 19,\n",
      "  twenty: 20,\n",
      "  thirty: 21,\n",
      "  forty: 22,\n",
      "  fifty: 23,\n",
      "  sixty: 24,\n",
      "  seventy: 25,\n",
      "  eighty: 26,\n",
      "  ninety: 27,\n",
      "  hundred: 28,\n",
      "  thousand: 29\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const word2idx={};\n",
    "vocab.forEach((word,idx)=>word2idx[word]=idx);\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dense-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   0,  1,  2,  1,  3, 1,  4,  1,  5,  1,  6, 1,\n",
      "   7,  1,  8,  1,  9, 1, 10,  1, 11,  1, 12, 1,\n",
      "  13,  1, 14,  1, 15, 1, 16,  1, 17,  1, 18, 1,\n",
      "  19,  1, 20,  1, 20, 0,  1, 20,  2,  1, 20, 3,\n",
      "   1, 20,  4,  1, 20, 5,  1, 20,  6,  1, 20, 7,\n",
      "   1, 20,  8,  1, 20, 9,  1, 21,  1, 21,  0, 1,\n",
      "  21,  2,  1, 21,  3, 1, 21,  4,  1, 21,  5, 1,\n",
      "  21,  6,  1, 21,  7, 1, 21,  8,  1, 21,  9, 1,\n",
      "  22,  1, 22,  0,\n",
      "  ... 10921 more items\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const nums=tokens.map(e=>word2idx[e]);\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitting-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "const data=[[],[],[],[]];\n",
    "for (let i=0; i<nums.length-4; i+=3) {\n",
    "    data[0].push(nums[i]);\n",
    "    data[1].push(nums[i+1]);\n",
    "    data[2].push(nums[i+2]);\n",
    "    data[3].push(nums[i+3]);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "similar-muscle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mostCommonToken [ '.', 1999 ] 0.18138099990926412\n"
     ]
    }
   ],
   "source": [
    "const tokenCounter={};\n",
    "vocab.forEach(token=>tokenCounter[token]=0);\n",
    "tokens.forEach(token=>tokenCounter[token]++);\n",
    "let mostCommonToken=[null,0];\n",
    "for (let key in tokenCounter) {\n",
    "    if (tokenCounter[key]>mostCommonToken[1]) {\n",
    "        mostCommonToken=[key,tokenCounter[key]];\n",
    "    }\n",
    "}\n",
    "console.log('mostCommonToken', mostCommonToken, mostCommonToken[1]/tokens.length);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-easter",
   "metadata": {},
   "source": [
    "&uarr; if we can get better than 0.18 accuracy, our model will be doing better than predicting the most common token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "guided-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "Imports we need in rnn.module.js\n",
    "*/\n",
    "import {round,flatten,exp,shape,transpose,dotProduct,randn,full,zeros,mean,reshape,argmax} from './src/util.module.js';\n",
    "import {normalize,identity,meanAndStandardDeviation} from './src/util.module.js';\n",
    "import {matrixSum1d,matrixSum2d,matrixSubtract1d,matrixSubtract2d,matrixMultiply1d,matrixMultiply2d} from './src/util.module.js';\n",
    "import {head,tail,parseCsv,IRIS_CLASS_MAP,IrisRowHandler,shuffle,split,batches} from './src/data.module.js';\n",
    "import {accuracy,Sigmoid,MSE,ReLU,Linear,Learner} from './src/nn.module.js';\n",
    "import {BinaryCrossEntropyLoss,CrossEntropyLoss} from './src/nn.module.js';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "centered-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "A Linear that can be called multiple times during a forward pass.\n",
    "*/\n",
    "class MultiCallLinear extends Linear{\n",
    "    constructor(inputDim,numHidden=1,bias=true) {\n",
    "        super(inputDim,numHidden,bias);\n",
    "        this.xHistory=[];\n",
    "        this.weightsGradients=null;\n",
    "        this.biasGradients=null;\n",
    "    }\n",
    "    forward(x) {\n",
    "        this.xHistory.push(x);\n",
    "        return super.forward(x);\n",
    "    }\n",
    "    backward(gradient) {\n",
    "        if (this.xHistory.length == 0) {\n",
    "            throw `this.xHistory is empty`;\n",
    "        }\n",
    "        this.x=this.xHistory.pop();\n",
    "        super.backward(gradient);\n",
    "        this.weightsGradients=(this.weightsGradients == null) \n",
    "                ? this.weightsGradient\n",
    "                : matrixSum2d(this.weightsGradient,this.weightsGradients);\n",
    "        this.biasGradients=(this.biasGradients == null) \n",
    "                ? this.biasGradient\n",
    "                : matrixSum1d(this.biasGradient,this.biasGradients);\n",
    "        // Note: we're not keeping x gradients\n",
    "        return this.xGradient;\n",
    "    }\n",
    "    update(lr) {\n",
    "        if (this.xHistory.length != 0) {\n",
    "            throw `forward has been called ${this.xHistory.length} times more than backward`;\n",
    "        }\n",
    "        super.weightsGradient=this.weightsGradients;\n",
    "        super.biasGradient=this.biasGradients;\n",
    "        super.update(lr);\n",
    "        this.weightsGradients=null;\n",
    "        this.biasGradients=null;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-spoke",
   "metadata": {},
   "source": [
    "## TODO: test MultiCallLinear &uarr;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-acoustic",
   "metadata": {},
   "source": [
    "## First recurrent model - predict next word from previous 3 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pressing-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel2 {\n",
    "    constructor(vocab_sz, n_hidden) {\n",
    "        this.i_h = new MultiCallLinear(vocab_sz, n_hidden);\n",
    "        this.h_h = new MultiCallLinear(n_hidden, n_hidden);\n",
    "        this.h_o = new Linear(n_hidden, vocab_sz);\n",
    "        this.non_linear = new ReLU();\n",
    "        this.oneHotLookup = normalize(identity(vocab_sz));\n",
    "    }\n",
    "    \n",
    "    toOneHot(x) {\n",
    "        return x.map(e=>this.oneHotLookup[e]);\n",
    "    }\n",
    "    \n",
    "    forward(x) {\n",
    "        let h=0;\n",
    "        for (let i=0; i<3; i++) {\n",
    "            h = matrixSum2d(this.i_h.forward(this.toOneHot(x[i])), h);\n",
    "            h = this.non_linear.forward(this.h_h.forward(h));\n",
    "        }\n",
    "        return this.h_o.forward(h);\n",
    "    }\n",
    "    \n",
    "    backward(gradients) {\n",
    "        let g=this.h_o.backward(gradients);\n",
    "        for (let i=2; i>=0; i--) {\n",
    "            g=this.non_linear.backward(g);\n",
    "            g=this.h_h.backward(g);\n",
    "            // TODO: matrix sum\n",
    "            this.i_h.backward(g);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    update(lr) {\n",
    "        this.i_h.update(lr);\n",
    "        this.h_h.update(lr);\n",
    "        this.h_o.update(lr);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-sucking",
   "metadata": {},
   "source": [
    "`constructor`\n",
    "- normalizing the one-hot lookup seems to make training more stable and slightly more accurate\n",
    "\n",
    "`forward`\n",
    "- If `i_h` was an embedding we wouldn't need `toOneHot`\n",
    "- When we `matrixSum2d(i_h.forward(), h)` we put `h` on the right so that the initial value `0` is re-shaped to match the shape of the output of `i_h` (which is `[n_hidden,n_hidden]`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excellent-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 9.463804802334936 accuracy 0.021780560849441872\n",
      "epoch 1 loss 4.423252671947863 accuracy 0.11952082766131228\n",
      "epoch 2 loss 2.952456813105928 accuracy 0.22951265995099374\n",
      "epoch 3 loss 2.5801670238430106 accuracy 0.29267628641437515\n",
      "epoch 4 loss 2.3919609654912244 accuracy 0.39940103457664033\n",
      "epoch 5 loss 2.249359315894222 accuracy 0.4252654505853526\n",
      "epoch 6 loss 2.160554415187405 accuracy 0.45657500680642527\n",
      "epoch 7 loss 2.091707674548205 accuracy 0.4707323713585625\n",
      "epoch 8 loss 2.041981511649167 accuracy 0.4778110536346311\n",
      "epoch 9 loss 1.997407597559624 accuracy 0.4756329975496869\n",
      "epoch 10 loss 1.9642968522151296 accuracy 0.4938742172610945\n",
      "epoch 11 loss 1.9282146869101724 accuracy 0.4848897359106997\n",
      "epoch 12 loss 1.9013480879692413 accuracy 0.5028586986114892\n",
      "epoch 13 loss 1.8767241613264303 accuracy 0.476449768581541\n",
      "epoch 14 loss 1.8811034015094106 accuracy 0.4857065069425538\n",
      "epoch 15 loss 1.8723834145306242 accuracy 0.465287231146202\n",
      "epoch 16 loss 1.9324484061780247 accuracy 0.46474271712496595\n",
      "epoch 17 loss 1.8084852237467122 accuracy 0.49251293220800435\n",
      "epoch 18 loss 1.7781363311630554 accuracy 0.523277974407841\n",
      "epoch 19 loss 1.7386943471004588 accuracy 0.5159270351211543\n"
     ]
    }
   ],
   "source": [
    "let lossFn=new CrossEntropyLoss();\n",
    "let model=new LMModel2(vocab.length,28);\n",
    "let yTrue=data[3];\n",
    "for (let epoch=0; epoch<20; epoch++) {\n",
    "    let yPred=model.forward(data);\n",
    "    let lossValue=lossFn.forward(yPred,yTrue);\n",
    "    console.log('epoch',epoch,'loss',lossValue,'accuracy',accuracy(yPred,yTrue));\n",
    "    model.backward(lossFn.backward());\n",
    "    model.update(3e-1);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-pension",
   "metadata": {},
   "source": [
    "```\n",
    "let lossFn=new CrossEntropyLoss();\n",
    "let model=new LMModel2(vocab.length,28);\n",
    "let yTrue=data[3];\n",
    "for (let epoch=0; epoch<10; epoch++) {\n",
    "    let yPred=model.forward(data);\n",
    "    let lossValue=lossFn.forward(yPred,yTrue);\n",
    "    console.log('epoch',epoch,'loss',lossValue,'accuracy',accuracy(yPred,yTrue));\n",
    "    model.backward(lossFn.backward());\n",
    "    model.update(3e-1);\n",
    "}\n",
    "epoch 0 loss 3.2278166493704066 accuracy 0.07296487884563027\n",
    "...\n",
    "epoch 9 loss 2.3760766295703397 accuracy 0.43642798802069155\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-blocking",
   "metadata": {},
   "source": [
    "### What if we normalize the signal/grads coming back from loss?\n",
    "\n",
    "`gradients` is used in a `dotProduct` to calculate weights and x gradients or each `Linear`-  might we get better training stability by normalizing the gradients we get back from the loss function?\n",
    "\n",
    "Adding the following to the top of `backward` shows us the mean and standard deviation of `gradients` and then normalizes them.\n",
    "\n",
    "```\n",
    "        let stats=meanAndStandardDeviation(flatten(gradients))\n",
    "        console.log('grads from loss function [mean,std]',stats);\n",
    "        gradients=normalize(gradients);\n",
    "```\n",
    "\n",
    "This increases the standard deviation from ~0.2 to 1.0 so we reduce `lr` by about 5x - which trains pretty much like it did before (o:\n",
    "\n",
    "Maybe this will help more when we try longer sequence lengths?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "jslab"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "text/javascript",
   "name": "javascript",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
